<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Transformer Architecture Visualization</title>
    <style>
        body {
            font-family: 'Arial', sans-serif;
            margin: 0;
            padding: 20px;
            background-color: #f5f8fa;
            color: #333;
            line-height: 1.5;
        }
        .container {
            max-width: 1100px;
            margin: 0 auto;
            background-color: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }
        h1, h2, h3 {
            color: #2c3e50;
            text-align: center;
        }
        h1 {
            margin-bottom: 20px;
        }
        h2 {
            margin: 40px 0 20px;
        }
        .explanation {
            background-color: #e8f4f8;
            padding: 15px;
            border-radius: 8px;
            margin-bottom: 30px;
            font-size: 16px;
        }
        .control-panel {
            display: flex;
            flex-wrap: wrap;
            gap: 15px;
            justify-content: space-between;
            margin-bottom: 20px;
            background-color: #f0f0f0;
            padding: 15px;
            border-radius: 8px;
        }
        .control-group {
            display: flex;
            flex-direction: column;
            min-width: 200px;
        }
        label {
            margin-bottom: 5px;
            font-weight: bold;
        }
        select, input {
            padding: 8px;
            border-radius: 4px;
            border: 1px solid #ddd;
        }
        .transformer-container {
            display: flex;
            justify-content: space-between;
            margin: 30px 0;
            position: relative;
        }
        .architecture-section {
            flex: 1;
            display: flex;
            flex-direction: column;
            align-items: center;
            max-width: 48%;
        }
        .section-title {
            font-weight: bold;
            font-size: 18px;
            margin-bottom: 20px;
            color: #3498db;
        }
        .layer {
            width: 100%;
            margin-bottom: 20px;
            position: relative;
        }
        .layer-box {
            background-color: #f0f0f0;
            border: 2px solid #3498db;
            border-radius: 10px;
            padding: 15px;
            margin-bottom: 10px;
            position: relative;
            z-index: 2;
            transition: all 0.3s;
            cursor: pointer;
        }
        .layer-box:hover {
            transform: scale(1.02);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }
        .layer-title {
            font-weight: bold;
            margin-bottom: 5px;
            text-align: center;
        }
        .active-layer {
            background-color: #d5f0ff;
            border-color: #2980b9;
            box-shadow: 0 0 10px rgba(52, 152, 219, 0.5);
        }
        .layer-content {
            display: flex;
            justify-content: space-around;
            align-items: center;
        }
        .sublayer {
            padding: 10px;
            border-radius: 5px;
            background-color: rgba(255, 255, 255, 0.7);
            text-align: center;
            font-size: 14px;
            white-space: nowrap;
        }
        .connections {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            pointer-events: none;
            z-index: 1;
        }
        .token-flow {
            display: flex;
            justify-content: space-around;
            width: 100%;
            margin-bottom: 20px;
            padding: 10px 0;
        }
        .token {
            padding: 8px 12px;
            background-color: #3498db;
            color: white;
            border-radius: 5px;
            font-weight: bold;
            text-align: center;
            transition: all 0.3s;
        }
        .token-focused {
            background-color: #e74c3c;
            transform: scale(1.1);
            box-shadow: 0 0 10px rgba(231, 76, 60, 0.5);
        }
        .token-arrow {
            position: absolute;
            left: 50%;
            transform: translateX(-50%);
            font-size: 24px;
            color: #7f8c8d;
        }
        .explanation-panel {
            background-color: #f9f9f9;
            border-left: 4px solid #3498db;
            padding: 20px;
            margin: 40px 0;
            border-radius: 0 8px 8px 0;
        }
        .explanation-panel h3 {
            margin-top: 0;
            text-align: left;
        }
        .step-container {
            margin-top: 40px;
            display: flex;
            flex-wrap: wrap;
            gap: 20px;
        }
        .step-card {
            flex: 1;
            min-width: 200px;
            padding: 15px;
            background-color: #f0f0f0;
            border-radius: 8px;
            position: relative;
        }
        .step-number {
            position: absolute;
            top: -10px;
            left: -10px;
            width: 30px;
            height: 30px;
            background-color: #3498db;
            color: white;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: bold;
        }
        .animation-control {
            display: flex;
            justify-content: center;
            margin: 20px 0;
        }
        .animation-btn {
            padding: 10px 20px;
            background-color: #2ecc71;
            color: white;
            border: none;
            border-radius: 5px;
            font-size: 16px;
            cursor: pointer;
            transition: background-color 0.3s;
        }
        .animation-btn:hover {
            background-color: #27ae60;
        }
        .animation-btn:disabled {
            background-color: #95a5a6;
            cursor: not-allowed;
        }
        .component-detail {
            display: none;
            margin-top: 50px;
            padding: 20px;
            background-color: #f9f9f9;
            border-radius: 8px;
        }
        .component-detail.active {
            display: block;
            animation: fadeIn 0.5s;
        }
        .detail-illustration {
            display: flex;
            justify-content: center;
            margin: 20px 0;
        }
        .detail-card {
            background-color: white;
            border: 1px solid #ddd;
            border-radius: 8px;
            padding: 20px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
            max-width: 600px;
            margin: 0 auto;
        }
        @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
        }
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.05); }
            100% { transform: scale(1); }
        }
        .pulse {
            animation: pulse 1s infinite;
        }
        .sequence-info {
            display: flex;
            justify-content: space-between;
            margin-top: 40px;
            padding: 15px;
            background-color: #f0f0f0;
            border-radius: 8px;
        }
        .sequence-box {
            flex: 1;
            margin: 0 10px;
            padding: 10px;
            background-color: white;
            border-radius: 5px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        }
        .sequence-title {
            font-weight: bold;
            margin-bottom: 10px;
            text-align: center;
        }
        .sequence-tokens {
            display: flex;
            flex-wrap: wrap;
            gap: 5px;
            justify-content: center;
        }
        .sequence-token {
            padding: 5px 8px;
            background-color: #3498db;
            color: white;
            border-radius: 4px;
            font-size: 14px;
        }
        .highlights {
            font-weight: bold;
            color: #e74c3c;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Interactive Transformer Architecture Visualization</h1>
        
        <div class="explanation">
            <p>The <span class="highlights">Transformer</span> is a neural network architecture introduced in the paper "Attention Is All You Need" (2017). It revolutionized NLP by enabling parallel processing of sequences and capturing long-range dependencies without recurrence. This visualization shows the complete architecture with both encoder and decoder components.</p>
        </div>
        
        <div class="control-panel">
            <div class="control-group">
                <label for="model-type">Model Type:</label>
                <select id="model-type">
                    <option value="encoder-decoder">Encoder-Decoder (Translation, Summarization)</option>
                    <option value="encoder-only">Encoder-only (BERT, RoBERTa)</option>
                    <option value="decoder-only">Decoder-only (GPT, LLaMA)</option>
                </select>
            </div>
            
            <div class="control-group">
                <label for="example-select">Example:</label>
                <select id="example-select">
                    <option value="translation">Translation (English → French)</option>
                    <option value="summarization">Summarization</option>
                    <option value="classification">Text Classification</option>
                </select>
            </div>
            
            <div class="control-group">
                <label for="layer-count">Number of Layers:</label>
                <input type="range" id="layer-count" min="1" max="6" value="3" step="1">
                <span id="layer-count-value">3</span>
            </div>
        </div>
        
        <div class="animation-control">
            <button id="animate-btn" class="animation-btn">▶️ Animate Data Flow</button>
        </div>
        
        <div class="sequence-info">
            <div class="sequence-box">
                <div class="sequence-title">Input Sequence</div>
                <div class="sequence-tokens" id="input-sequence">
                    <!-- Will be populated dynamically -->
                </div>
            </div>
            
            <div class="sequence-box">
                <div class="sequence-title">Output Sequence</div>
                <div class="sequence-tokens" id="output-sequence">
                    <!-- Will be populated dynamically -->
                </div>
            </div>
        </div>
        
        <div class="transformer-container">
            <!-- SVG for connection lines -->
            <svg class="connections" id="architecture-connections"></svg>
            
            <div class="architecture-section" id="encoder-section">
                <div class="section-title">Encoder</div>
                
                <!-- Input Embeddings -->
                <div class="token-flow" id="encoder-tokens">
                    <!-- Will be populated dynamically -->
                </div>
                
                <div class="layer">
                    <div class="layer-box" id="input-embeddings" data-component="embeddings">
                        <div class="layer-title">Input Embeddings + Positional Encoding</div>
                    </div>
                </div>
                
                <!-- Encoder Layers (will be generated dynamically) -->
                <div id="encoder-layers">
                    <!-- Will be populated dynamically -->
                </div>
            </div>
            
            <div class="architecture-section" id="decoder-section">
                <div class="section-title">Decoder</div>
                
                <!-- Output Embeddings -->
                <div class="token-flow" id="decoder-tokens">
                    <!-- Will be populated dynamically -->
                </div>
                
                <div class="layer">
                    <div class="layer-box" id="output-embeddings" data-component="embeddings">
                        <div class="layer-title">Output Embeddings + Positional Encoding</div>
                    </div>
                </div>
                
                <!-- Decoder Layers (will be generated dynamically) -->
                <div id="decoder-layers">
                    <!-- Will be populated dynamically -->
                </div>
                
                <!-- Linear Layer -->
                <div class="layer">
                    <div class="layer-box" id="linear-layer" data-component="linear">
                        <div class="layer-title">Linear Layer</div>
                    </div>
                </div>
                
                <!-- Softmax Layer -->
                <div class="layer">
                    <div class="layer-box" id="softmax-layer" data-component="softmax">
                        <div class="layer-title">Softmax</div>
                    </div>
                </div>
            </div>
        </div>
        
        <!-- Component Details Section -->
        <div id="component-details">
            <div class="component-detail" id="embeddings-detail">
                <h3>Token & Positional Embeddings</h3>
                <p>Tokens are first converted to vector representations (embeddings). Then, positional encodings are added to incorporate information about the position of each token in the sequence.</p>
                <div class="detail-illustration">
                    <div class="detail-card">
                        <p><strong>Token Embedding:</strong> Maps each token to a vector (typically 512 to 1024 dimensions)</p>
                        <p><strong>Positional Encoding:</strong> Uses sine and cosine functions of different frequencies</p>
                        <p><strong>Combined:</strong> Token Embedding + Positional Encoding → Final Embedding</p>
                    </div>
                </div>
            </div>
            
            <div class="component-detail" id="self-attention-detail">
                <h3>Multi-Head Self-Attention</h3>
                <p>Self-attention allows the model to weigh the importance of different tokens when encoding each token. Multi-head attention performs this process in parallel with different learned projections.</p>
                <div class="detail-illustration">
                    <div class="detail-card">
                        <p><strong>For each token:</strong> Create query (Q), key (K), and value (V) vectors</p>
                        <p><strong>Attention scores:</strong> Calculate how much to attend to each token (Q·K<sup>T</sup>)</p>
                        <p><strong>Multiple heads:</strong> 8-16 parallel attention mechanisms focusing on different aspects</p>
                        <p><strong>Output:</strong> Weighted sum of value vectors based on attention scores</p>
                    </div>
                </div>
            </div>
            
            <div class="component-detail" id="cross-attention-detail">
                <h3>Cross-Attention</h3>
                <p>Cross-attention allows the decoder to focus on relevant parts of the input sequence. It uses queries from the decoder and keys/values from the encoder.</p>
                <div class="detail-illustration">
                    <div class="detail-card">
                        <p><strong>Queries:</strong> From the decoder (current token being processed)</p>
                        <p><strong>Keys and Values:</strong> From the encoder output (input sequence representation)</p>
                        <p><strong>Mechanism:</strong> Similar to self-attention, but connects encoder to decoder</p>
                        <p><strong>Benefit:</strong> Allows decoder to focus on relevant parts of the input sequence</p>
                    </div>
                </div>
            </div>
            
            <div class="component-detail" id="ffn-detail">
                <h3>Feed-Forward Network</h3>
                <p>Each position is processed independently by a two-layer feed-forward network, applying non-linear transformations to the attention outputs.</p>
                <div class="detail-illustration">
                    <div class="detail-card">
                        <p><strong>Structure:</strong> Two linear transformations with a ReLU activation in between</p>
                        <p><strong>First projection:</strong> Input dimension → Larger dimension (typically 4x input size)</p>
                        <p><strong>Second projection:</strong> Larger dimension → Original input dimension</p>
                        <p><strong>Applied:</strong> Independently to each position in the sequence</p>
                    </div>
                </div>
            </div>
            
            <div class="component-detail" id="layer-norm-detail">
                <h3>Layer Normalization</h3>
                <p>Normalizes the inputs across the feature dimension, helping stabilize and accelerate training by preventing internal covariate shift.</p>
                <div class="detail-illustration">
                    <div class="detail-card">
                        <p><strong>Function:</strong> Normalizes each token's embedding to have mean=0 and variance=1</p>
                        <p><strong>Formula:</strong> LayerNorm(x) = γ * (x - μ) / (σ + ε) + β</p>
                        <p><strong>Placement:</strong> Applied before main operations in each sublayer</p>
                        <p><strong>Benefit:</strong> Stabilizes training and reduces dependence on careful initialization</p>
                    </div>
                </div>
            </div>
            
            <div class="component-detail" id="residual-detail">
                <h3>Residual Connections</h3>
                <p>Allows information to flow directly from earlier layers to later layers, helping combat vanishing gradients and enabling training of deeper networks.</p>
                <div class="detail-illustration">
                    <div class="detail-card">
                        <p><strong>Formula:</strong> Output = Sublayer(x) + x</p>
                        <p><strong>Benefit:</strong> Helps gradient flow during backpropagation</p>
                        <p><strong>Implementation:</strong> Add the input to the output of each sublayer</p>
                        <p><strong>Usage:</strong> Applied around both self-attention and feed-forward networks</p>
                    </div>
                </div>
            </div>
            
            <div class="component-detail" id="linear-detail">
                <h3>Linear Layer</h3>
                <p>Projects the decoder output to the vocabulary space, preparing for the prediction of the next token.</p>
                <div class="detail-illustration">
                    <div class="detail-card">
                        <p><strong>Input:</strong> Decoder output vectors (dimension = model size)</p>
                        <p><strong>Output:</strong> Logits for each token in vocabulary (dimension = vocabulary size)</p>
                        <p><strong>Parameters:</strong> Weight matrix of size [model_size × vocabulary_size]</p>
                        <p><strong>Note:</strong> Often shares weights with the embedding layer</p>
                    </div>
                </div>
            </div>
            
            <div class="component-detail" id="softmax-detail">
                <h3>Softmax Layer</h3>
                <p>Converts logits into a probability distribution over the vocabulary, allowing the model to predict the most likely next token.</p>
                <div class="detail-illustration">
                    <div class="detail-card">
                        <p><strong>Function:</strong> Converts raw scores to probabilities</p>
                        <p><strong>Formula:</strong> softmax(x<sub>i</sub>) = e<sup>x<sub>i</sub></sup> / Σ e<sup>x<sub>j</sub></sup></p>
                        <p><strong>Output:</strong> Probability distribution (all values sum to 1)</p>
                        <p><strong>Usage:</strong> During training, compared to true next token for loss calculation</p>
                    </div>
                </div>
            </div>
        </div>
        
        <div class="explanation-panel">
            <h3>Key Innovations of the Transformer Architecture</h3>
            <p>1. <strong>Parallelization:</strong> Unlike RNNs, transformers process all tokens simultaneously, enabling much faster training.</p>
            <p>2. <strong>Long-range dependencies:</strong> Self-attention directly connects any two positions in a sequence, regardless of their distance.</p>
            <p>3. <strong>Multi-head attention:</strong> Multiple attention mechanisms allow the model to focus on different aspects of the input simultaneously.</p>
            <p>4. <strong>Positional encoding:</strong> Since the model has no inherent notion of sequence order, positional information is added explicitly.</p>
        </div>
        
        <div class="step-container">
            <div class="step-card">
                <div class="step-number">1</div>
                <h4>Tokenization</h4>
                <p>Convert text to tokens, each representing a word, subword, or character.</p>
            </div>
            
            <div class="step-card">
                <div class="step-number">2</div>
                <h4>Embedding</h4>
                <p>Map tokens to vectors and add positional information.</p>
            </div>
            
            <div class="step-card">
                <div class="step-number">3</div>
                <h4>Encoder Processing</h4>
                <p>Process input sequence through multiple layers of self-attention and feed-forward networks.</p>
            </div>
            
            <div class="step-card">
                <div class="step-number">4</div>
                <h4>Decoder Processing</h4>
                <p>Generate output tokens one at a time, using self-attention and cross-attention to the encoder's output.</p>
            </div>
        </div>
    </div>

    <script>
        // Sample data for visualization
        const examples = {
            translation: {
                input: ["I", "enjoy", "learning", "about", "transformers", "."],
                output: ["J'", "aime", "apprendre", "sur", "les", "transformers", "."]
            },
            summarization: {
                input: ["The", "transformer", "architecture", "was", "introduced", "in", "2017", "."],
                output: ["Transformer", "introduced", "2017", "."]
            },
            classification: {
                input: ["This", "movie", "was", "incredible", "and", "entertaining", "."],
                output: ["Positive"]
            }
        };
        
        // Function to initialize the architecture visualization
        function initArchitecture() {
            updateLayerCount();
            updateModelType();
            updateExampleSequences();
            
            // Add event listeners
            document.getElementById('layer-count').addEventListener('input', updateLayerCount);
            document.getElementById('model-type').addEventListener('change', updateModelType);
            document.getElementById('example-select').addEventListener('change', updateExampleSequences);
            document.getElementById('animate-btn').addEventListener('click', animateDataFlow);
            
            // Add click handlers for layer components
            document.querySelectorAll('.layer-box').forEach(box => {
                const componentType = box.getAttribute('data-component');
                if (componentType) {
                    box.addEventListener('click', () => showComponentDetail(componentType));
                }
            });
        }
        
        // Update the number of encoder and decoder layers
        function updateLayerCount() {
            const layerCount = parseInt(document.getElementById('layer-count').value);
            document.getElementById('layer-count-value').textContent = layerCount;
            
            // Generate encoder layers
            const encoderLayers = document.getElementById('encoder-layers');
            encoderLayers.innerHTML = '';
            
            for (let i = 0; i < layerCount; i++) {
                const layer = document.createElement('div');
                layer.className = 'layer';
                layer.innerHTML = `
                    <div class="layer-box" data-component="self-attention">
                        <div class="layer-title">Encoder Layer ${i+1}</div>
                        <div class="layer-content">
                            <div class="sublayer">Self-Attention</div>
                            <div class="sublayer">Feed-Forward</div>
                        </div>
                    </div>
                `;
                encoderLayers.appendChild(layer);
            }
            
            // Generate decoder layers
            const decoderLayers = document.getElementById('decoder-layers');
            decoderLayers.innerHTML = '';
            
            for (let i = 0; i < layerCount; i++) {
                const layer = document.createElement('div');
                layer.className = 'layer';
                layer.innerHTML = `
                    <div class="layer-box" data-component="cross-attention">
                        <div class="layer-title">Decoder Layer ${i+1}</div>
                        <div class="layer-content">
                            <div class="sublayer">Self-Attention</div>
                            <div class="sublayer">Cross-Attention</div>
                            <div class="sublayer">Feed-Forward</div>
                        </div>
                    </div>
                `;
                decoderLayers.appendChild(layer);
            }
            
            // Reattach click listeners
            document.querySelectorAll('.layer-box').forEach(box => {
                const componentType = box.getAttribute('data-component');
                if (componentType) {
                    box.addEventListener('click', () => showComponentDetail(componentType));
                }
            });
        }
        
        // Update architecture based on model type selection
        function updateModelType() {
            const modelType = document.getElementById('model-type').value;
            const encoderSection = document.getElementById('encoder-section');
            const decoderSection = document.getElementById('decoder-section');
            
            switch (modelType) {
                case 'encoder-decoder':
                    encoderSection.style.display = 'flex';
                    decoderSection.style.display = 'flex';
                    break;
                case 'encoder-only':
                    encoderSection.style.display = 'flex';
                    decoderSection.style.display = 'none';
                    break;
                case 'decoder-only':
                    encoderSection.style.display = 'none';
                    decoderSection.style.display = 'flex';
                    // Update the decoder layers to remove cross-attention for decoder-only models
                    document.querySelectorAll('#decoder-layers .layer-box').forEach(box => {
                        box.setAttribute('data-component', 'self-attention');
                        const content = box.querySelector('.layer-content');
                        content.innerHTML = `
                            <div class="sublayer">Self-Attention</div>
                            <div class="sublayer">Feed-Forward</div>
                        `;
                        
                        // Reattach click listeners
                        box.addEventListener('click', () => showComponentDetail('self-attention'));
                    });
                    break;
            }
        }
        
        // Update example sequences in the visualization
        function updateExampleSequences() {
            const exampleType = document.getElementById('example-select').value;
            const example = examples[exampleType];
            
            // Update input sequence
            const inputSequence = document.getElementById('input-sequence');
            inputSequence.innerHTML = '';
            example.input.forEach(token => {
                const tokenElement = document.createElement('div');
                tokenElement.className = 'sequence-token';
                tokenElement.textContent = token;
                inputSequence.appendChild(tokenElement);
            });
            
            // Update output sequence
            const outputSequence = document.getElementById('output-sequence');
            outputSequence.innerHTML = '';
            example.output.forEach(token => {
                const tokenElement = document.createElement('div');
                tokenElement.className = 'sequence-token';
                tokenElement.textContent = token;
                outputSequence.appendChild(tokenElement);
            });
            
            // Update tokens in the architecture diagram
            updateTokensInArchitecture(example);
        }
        
        // Update tokens shown in the architecture diagram
        function updateTokensInArchitecture(example) {
            // Update encoder tokens
            const encoderTokens = document.getElementById('encoder-tokens');
            encoderTokens.innerHTML = '';
            example.input.forEach(token => {
                const tokenElement = document.createElement('div');
                tokenElement.className = 'token';
                tokenElement.textContent = token;
                encoderTokens.appendChild(tokenElement);
            });
            
            // Update decoder tokens
            const decoderTokens = document.getElementById('decoder-tokens');
            decoderTokens.innerHTML = '';
            example.output.forEach(token => {
                const tokenElement = document.createElement('div');
                tokenElement.className = 'token';
                tokenElement.textContent = token;
                decoderTokens.appendChild(tokenElement);
            });
        }
        
        // Show component details when a layer is clicked
        function showComponentDetail(componentType) {
            // Hide all details first
            document.querySelectorAll('.component-detail').forEach(detail => {
                detail.classList.remove('active');
            });
            
            // Show the selected component detail
            const detailElement = document.getElementById(`${componentType}-detail`);
            if (detailElement) {
                detailElement.classList.add('active');
                
                // Scroll to the detail section
                detailElement.scrollIntoView({ behavior: 'smooth', block: 'center' });
            }
            
            // Remove active class from all layers
            document.querySelectorAll('.layer-box').forEach(layer => {
                layer.classList.remove('active-layer');
            });
            
            // Add active class to layers of the same type
            document.querySelectorAll(`.layer-box[data-component="${componentType}"]`).forEach(layer => {
                layer.classList.add('active-layer');
            });
        }
        
        // Animate data flow through the transformer
        function animateDataFlow() {
            const animateBtn = document.getElementById('animate-btn');
            animateBtn.disabled = true;
            animateBtn.textContent = '⏳ Animating...';
            
            // Get all layers in order
            const layers = [
                document.getElementById('input-embeddings'),
                ...document.querySelectorAll('#encoder-layers .layer-box'),
                document.getElementById('output-embeddings'),
                ...document.querySelectorAll('#decoder-layers .layer-box'),
                document.getElementById('linear-layer'),
                document.getElementById('softmax-layer')
            ].filter(layer => layer && layer.offsetParent !== null); // Only visible layers
            
            // Get all tokens
            const encoderTokens = document.querySelectorAll('#encoder-tokens .token');
            const decoderTokens = document.querySelectorAll('#decoder-tokens .token');
            
            // Animation sequence
            let step = 0;
            const totalSteps = layers.length;
            
            const intervalId = setInterval(() => {
                // Reset all layers
                document.querySelectorAll('.layer-box').forEach(layer => {
                    layer.classList.remove('active-layer', 'pulse');
                });
                
                // Reset all tokens
                encoderTokens.forEach(token => token.classList.remove('token-focused'));
                decoderTokens.forEach(token => token.classList.remove('token-focused'));
                
                // Activate current layer
                if (step < layers.length) {
                    const currentLayer = layers[step];
                    currentLayer.classList.add('active-layer', 'pulse');
                    
                    // Show related component detail
                    showComponentDetail(currentLayer.getAttribute('data-component'));
                    
                    // Highlight related tokens
                    if (step < encoderTokens.length) {
                        // Focus on encoder tokens for encoder layers
                        encoderTokens[step].classList.add('token-focused');
                    } else if (step - encoderTokens.length < decoderTokens.length) {
                        // Focus on decoder tokens for decoder layers
                        decoderTokens[step - encoderTokens.length].classList.add('token-focused');
                    }
                }
                
                step++;
                
                if (step > totalSteps) {
                    clearInterval(intervalId);
                    animateBtn.disabled = false;
                    animateBtn.textContent = '▶️ Animate Data Flow';
                }
            }, 1500);
        }
        
        // Initialize the visualization when the page loads
        document.addEventListener('DOMContentLoaded', initArchitecture);
    </script>
</body>
</html>