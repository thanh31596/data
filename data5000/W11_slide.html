<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DATA5000 Week 11 - Application of Large Language Models 1</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif;
            background: #ffffff;
            color: #333;
            overflow: hidden;
        }

        .slide-container {
            width: 100vw;
            height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            position: relative;
        }

        .slide {
            display: none;
            width: 90%;
            max-width: 1200px;
            height: 85vh;
            padding: 60px;
            animation: fadeIn 0.5s;
        }

        .slide.active {
            display: flex;
            flex-direction: column;
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(20px); }
            to { opacity: 1; transform: translateY(0); }
        }

        h1 {
            color: #DC143C;
            font-size: 3em;
            margin-bottom: 30px;
            font-weight: 300;
            letter-spacing: -1px;
        }

        h2 {
            color: #DC143C;
            font-size: 2.2em;
            margin-bottom: 25px;
            font-weight: 400;
        }

        h3 {
            color: #DC143C;
            font-size: 1.5em;
            margin-bottom: 15px;
            margin-top: 20px;
        }

        p {
            font-size: 1.2em;
            line-height: 1.8;
            margin-bottom: 20px;
            color: #444;
        }

        .subtitle {
            font-size: 1.4em;
            color: #666;
            margin-bottom: 40px;
        }

        ul {
            list-style: none;
            padding-left: 0;
        }

        li {
            font-size: 1.2em;
            line-height: 1.8;
            margin-bottom: 15px;
            padding-left: 30px;
            position: relative;
        }

        li:before {
            content: "▪";
            color: #DC143C;
            position: absolute;
            left: 0;
            font-size: 1.5em;
        }

        .navigation {
            position: fixed;
            bottom: 30px;
            right: 30px;
            display: flex;
            gap: 15px;
            z-index: 1000;
        }

        button {
            background: #DC143C;
            color: white;
            border: none;
            padding: 12px 30px;
            font-size: 1em;
            cursor: pointer;
            border-radius: 5px;
            font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif;
            transition: background 0.3s;
        }

        button:hover {
            background: #B01030;
        }

        button:disabled {
            background: #ccc;
            cursor: not-allowed;
        }

        .slide-number {
            position: fixed;
            bottom: 30px;
            left: 30px;
            font-size: 1em;
            color: #666;
        }

        .comparison-box {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 30px;
            margin: 30px 0;
        }

        .box {
            padding: 25px;
            border: 2px solid #ddd;
            border-radius: 8px;
            background: #f9f9f9;
        }

        .box h3 {
            margin-top: 0;
        }

        .highlight-box {
            background: #fff5f5;
            border-left: 4px solid #DC143C;
            padding: 20px;
            margin: 20px 0;
        }

        /* Quiz Styles */
        .quiz-container {
            background: #f9f9f9;
            padding: 30px;
            border-radius: 8px;
            border: 2px solid #DC143C;
            margin-top: 30px;
        }

        .quiz-option {
            background: white;
            border: 2px solid #ddd;
            padding: 15px 20px;
            margin: 10px 0;
            cursor: pointer;
            border-radius: 5px;
            transition: all 0.3s;
            font-size: 1.1em;
        }

        .quiz-option:hover {
            border-color: #DC143C;
            background: #fff5f5;
        }

        .quiz-option.selected {
            border-color: #DC143C;
            background: #DC143C;
            color: white;
        }

        .quiz-option.correct {
            border-color: #28a745;
            background: #d4edda;
            color: #155724;
        }

        .quiz-option.incorrect {
            border-color: #dc3545;
            background: #f8d7da;
            color: #721c24;
        }

        .quiz-feedback {
            margin-top: 20px;
            padding: 15px;
            border-radius: 5px;
            font-size: 1.1em;
            display: none;
        }

        .quiz-feedback.show {
            display: block;
        }

        .quiz-feedback.correct {
            background: #d4edda;
            color: #155724;
            border: 1px solid #c3e6cb;
        }

        .quiz-feedback.incorrect {
            background: #f8d7da;
            color: #721c24;
            border: 1px solid #f5c6cb;
        }

        /* Visualization Styles */
        .flow-diagram {
            display: flex;
            align-items: center;
            justify-content: space-between;
            margin: 30px 0;
            padding: 20px;
        }

        .flow-step {
            flex: 1;
            text-align: center;
            padding: 20px;
            background: #f9f9f9;
            border: 2px solid #DC143C;
            border-radius: 8px;
            position: relative;
        }

        .flow-arrow {
            font-size: 2em;
            color: #DC143C;
            margin: 0 10px;
        }

        .vector-space {
            width: 100%;
            height: 300px;
            background: #f9f9f9;
            border: 2px solid #ddd;
            border-radius: 8px;
            position: relative;
            margin: 20px 0;
        }

        .vector-point {
            position: absolute;
            width: 12px;
            height: 12px;
            border-radius: 50%;
            transform: translate(-50%, -50%);
        }

        .vector-label {
            position: absolute;
            font-size: 0.9em;
            font-weight: bold;
            transform: translate(-50%, -150%);
        }

        .architecture-diagram {
            display: flex;
            flex-direction: column;
            gap: 15px;
            margin: 30px 0;
        }

        .layer {
            background: #f9f9f9;
            border: 2px solid #DC143C;
            padding: 15px;
            border-radius: 8px;
            text-align: center;
        }

        .benefits-grid {
            display: grid;
            grid-template-columns: repeat(3, 1fr);
            gap: 20px;
            margin: 30px 0;
        }

        .benefit-card {
            background: #f9f9f9;
            padding: 20px;
            border-radius: 8px;
            border-left: 4px solid #DC143C;
        }

        .comparison-table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }

        .comparison-table th {
            background: #DC143C;
            color: white;
            padding: 15px;
            text-align: left;
        }

        .comparison-table td {
            padding: 15px;
            border: 1px solid #ddd;
        }

        .comparison-table tr:nth-child(even) {
            background: #f9f9f9;
        }

        .code-preview {
            background: #2d2d2d;
            color: #f8f8f2;
            padding: 20px;
            border-radius: 8px;
            font-family: 'Courier New', monospace;
            font-size: 0.95em;
            overflow-x: auto;
            margin: 20px 0;
        }

        .process-steps {
            counter-reset: step-counter;
        }

        .process-step {
            counter-increment: step-counter;
            position: relative;
            padding-left: 60px;
            margin-bottom: 30px;
        }

        .process-step:before {
            content: counter(step-counter);
            position: absolute;
            left: 0;
            top: 0;
            width: 40px;
            height: 40px;
            background: #DC143C;
            color: white;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 1.5em;
            font-weight: bold;
        }

        .kbs-logo {
            position: fixed;
            bottom: 30px;
            left: 50%;
            transform: translateX(-50%);
            color: #666;
            font-size: 0.9em;
        }

        @media (max-height: 800px) {
            .slide {
                padding: 40px;
            }
            h1 {
                font-size: 2.5em;
            }
            h2 {
                font-size: 1.8em;
            }
            p, li {
                font-size: 1em;
            }
        }
    </style>
</head>
<body>
    <div class="slide-container">
        <!-- Slide 1: Title -->
        <div class="slide active">
            <h1>DATA5000</h1>
            <h1 style="margin-top: 20px;">Artificial Intelligence Programming in Business Analytics</h1>
            <div style="margin-top: 60px;">
                <h2>Application of Large Language Models 1</h2>
                <p class="subtitle">Workshop #11</p>
            </div>
            <div style="margin-top: auto;">
                <p style="font-size: 1em; color: #666;">Kaplan Business School</p>
            </div>
        </div>

        <!-- Slide 2: Learning Outcomes -->
        <div class="slide">
            <h2>Learning Outcomes</h2>
            <p>By the end of this workshop, you will be able to:</p>
            <ul>
                <li>Understand how to give LLMs access to your company's specific data</li>
                <li>Explain the concept of Retrieval-Augmented Generation (RAG)</li>
                <li>Describe how vector embeddings enable document similarity search</li>
                <li>Integrate ChromaDB, LangChain, and LLMs using Python</li>
                <li>Compare RAG and fine-tuning approaches for customizing LLMs</li>
                <li>Apply these techniques to real business scenarios</li>
            </ul>
        </div>

        <!-- Slide 3: The Business Problem -->
        <div class="slide">
            <h2>The Business Problem</h2>
            <div class="highlight-box">
                <h3>Scenario: TechCorp Customer Support</h3>
                <p>TechCorp has accumulated 10 years of customer service transcripts, product documentation, and technical troubleshooting guides. They want to use ChatGPT to help support agents quickly find solutions.</p>
            </div>
            <div class="comparison-box">
                <div class="box">
                    <h3>❌ Generic ChatGPT</h3>
                    <p><strong>Question:</strong> "How do I reset the TC-5000 router?"</p>
                    <p><strong>Response:</strong> "I don't have specific information about the TC-5000 router. Generally, routers can be reset by..."</p>
                    <p style="color: #dc3545; font-weight: bold;">Vague, unhelpful, potentially incorrect</p>
                </div>
                <div class="box">
                    <h3>✓ Customized LLM</h3>
                    <p><strong>Question:</strong> "How do I reset the TC-5000 router?"</p>
                    <p><strong>Response:</strong> "According to TechCorp Manual v3.2: Hold the reset button for 15 seconds, then power cycle. The LED will flash amber during reset."</p>
                    <p style="color: #28a745; font-weight: bold;">Accurate, specific, cited</p>
                </div>
            </div>
        </div>

        <!-- Slide 4: The Challenge -->
        <div class="slide">
            <h2>Why Generic LLMs Fall Short</h2>
            <p>ChatGPT and similar models have fundamental limitations for business applications:</p>
            <div class="benefits-grid">
                <div class="benefit-card">
                    <h3>No Access to Your Data</h3>
                    <p>LLMs only know what they were trained on. Your company's internal documents, customer data, and proprietary information don't exist in their knowledge base.</p>
                </div>
                <div class="benefit-card">
                    <h3>Outdated Information</h3>
                    <p>Training data has a cutoff date. New products, updated policies, or recent market changes are unknown to the model.</p>
                </div>
                <div class="benefit-card">
                    <h3>Hallucination Risk</h3>
                    <p>When LLMs don't know the answer, they often generate plausible-sounding but incorrect information—dangerous for business decisions.</p>
                </div>
            </div>
            <div class="highlight-box" style="margin-top: 30px;">
                <p><strong>The Solution:</strong> We need to give LLMs access to specific, relevant information when answering questions. This is where Retrieval-Augmented Generation comes in.</p>
            </div>
        </div>

        <!-- Slide 5: Two Paths to Customization -->
        <div class="slide">
            <h2>Two Approaches to Customizing LLMs</h2>
            <div class="comparison-box" style="margin-top: 50px;">
                <div class="box">
                    <h3>Approach 1: RAG</h3>
                    <h4 style="color: #DC143C; margin: 15px 0;">Retrieval-Augmented Generation</h4>
                    <p><strong>Concept:</strong> Give the LLM access to relevant documents when it answers questions</p>
                    <p><strong>Analogy:</strong> Open-book exam—the model can consult reference materials</p>
                    <p><strong>Best for:</strong> Frequently changing information, need for source citations, limited training data</p>
                </div>
                <div class="box">
                    <h3>Approach 2: Fine-Tuning</h3>
                    <h4 style="color: #DC143C; margin: 15px 0;">Model Training</h4>
                    <p><strong>Concept:</strong> Train the LLM on your specific domain and writing style</p>
                    <p><strong>Analogy:</strong> Intensive studying—the model internalizes the knowledge</p>
                    <p><strong>Best for:</strong> Stable knowledge domain, consistent style needed, large training datasets</p>
                </div>
            </div>
            <p style="margin-top: 30px; text-align: center; font-size: 1.3em; color: #DC143C;">Today's focus: RAG (We'll cover fine-tuning later)</p>
        </div>

        <!-- Quiz 1 -->
        <div class="slide">
            <h2>Knowledge Check 1</h2>
            <div class="quiz-container">
                <h3 style="margin-top: 0;">Why would a company need RAG or fine-tuning instead of using ChatGPT directly?</h3>
                <div class="quiz-option" data-quiz="1" data-answer="c" data-option="a">
                    A) ChatGPT is too expensive for business use
                </div>
                <div class="quiz-option" data-quiz="1" data-answer="c" data-option="b">
                    B) ChatGPT doesn't understand natural language well enough
                </div>
                <div class="quiz-option" data-quiz="1" data-answer="c" data-option="c">
                    C) ChatGPT doesn't have access to company-specific data and information
                </div>
                <div class="quiz-option" data-quiz="1" data-answer="c" data-option="d">
                    D) ChatGPT can only process text, not numbers
                </div>
                <div class="quiz-feedback"></div>
            </div>
        </div>

        <!-- Slide 6: How RAG Works (Simple) -->
        <div class="slide">
            <h2>How RAG Works: Simple Overview</h2>
            <div class="flow-diagram">
                <div class="flow-step">
                    <h3 style="margin: 0; font-size: 1.2em;">1. Question</h3>
                    <p style="margin-top: 10px; font-size: 1em;">User asks: "How do I reset the TC-5000?"</p>
                </div>
                <div class="flow-arrow">→</div>
                <div class="flow-step">
                    <h3 style="margin: 0; font-size: 1.2em;">2. Search</h3>
                    <p style="margin-top: 10px; font-size: 1em;">System finds relevant documents in database</p>
                </div>
                <div class="flow-arrow">→</div>
                <div class="flow-step">
                    <h3 style="margin: 0; font-size: 1.2em;">3. Retrieve</h3>
                    <p style="margin-top: 10px; font-size: 1em;">Pulls TC-5000 manual section</p>
                </div>
                <div class="flow-arrow">→</div>
                <div class="flow-step">
                    <h3 style="margin: 0; font-size: 1.2em;">4. Generate</h3>
                    <p style="margin-top: 10px; font-size: 1em;">LLM reads docs + question, generates answer</p>
                </div>
            </div>
            <div class="highlight-box" style="margin-top: 50px;">
                <h3>Key Insight</h3>
                <p>The LLM never "memorizes" your documents. Instead, it's given relevant excerpts in real-time to inform its response. This means it always has access to the latest information.</p>
            </div>
            <p style="margin-top: 30px;"><strong>Next question:</strong> How does the system know which documents are "relevant"?</p>
        </div>

        <!-- Slide 7: The Technical Challenge -->
        <div class="slide">
            <h2>The Technical Challenge</h2>
            <h3>How do computers find relevant documents?</h3>
            <div class="comparison-box" style="margin: 30px 0;">
                <div class="box">
                    <h3>How Humans Do It</h3>
                    <ul style="padding-left: 20px;">
                        <li>Read and understand content</li>
                        <li>Recognize concepts and context</li>
                        <li>Identify semantic similarity</li>
                        <li>Make connections between ideas</li>
                    </ul>
                    <p style="margin-top: 15px;">Example: We know "kitten" and "cat" are related even if the exact words don't match.</p>
                </div>
                <div class="box">
                    <h3>How Computers Need to Do It</h3>
                    <ul style="padding-left: 20px;">
                        <li>Convert text to numbers</li>
                        <li>Measure mathematical similarity</li>
                        <li>Find closest matches</li>
                        <li>Rank by relevance</li>
                    </ul>
                    <p style="margin-top: 15px;">Computers can't "read"—they need numerical representations to compare documents.</p>
                </div>
            </div>
            <div class="highlight-box">
                <h3>The Solution: Vector Embeddings</h3>
                <p>We convert each document into a unique "fingerprint" made of numbers. Documents with similar content get similar fingerprints, allowing computers to find related information mathematically.</p>
            </div>
        </div>

        <!-- Slide 8: Vector Embeddings Explained -->
        <div class="slide">
            <h2>Understanding Vector Embeddings</h2>
            <div class="highlight-box">
                <h3>What is an Embedding?</h3>
                <p>An embedding is a list of numbers that represents the meaning of text. Similar meanings result in similar numbers.</p>
            </div>
            <h3>Example: Pet-Related Words</h3>
            <div style="background: #f9f9f9; padding: 20px; border-radius: 8px; margin: 20px 0;">
                <p style="font-family: monospace; font-size: 1em;">
                    "cat"    = [1.6, 2.3, 4.7, ..., 8.2, 17.9]<br>
                    "kitten" = [1.6, 2.4, 4.7, ..., 8.3, 18.4]<br>
                    "dog"    = [1.5, 2.2, 4.8, ..., 8.1, 17.7]<br>
                    "puppy"  = [1.5, 2.3, 4.8, ..., 8.2, 18.0]<br>
                    "car"    = [8.2, 1.1, 2.3, ..., 4.5, 6.7]
                </p>
            </div>
            <p><strong>Notice:</strong> "cat" and "kitten" have very similar numbers. "car" is completely different. The algorithm captures semantic meaning!</p>
            <p style="margin-top: 20px;"><strong>For business documents:</strong> A product manual and a troubleshooting guide about the same product would have similar embeddings, making them easy to find together.</p>
        </div>

        <!-- Slide 9: Vector Space Visualization -->
        <div class="slide">
            <h2>Visualizing Vector Embeddings</h2>
            <p>In reality, embeddings have hundreds of dimensions. Here's a simplified 2D visualization:</p>
            <div class="vector-space">
                <!-- Kitchen items cluster -->
                <div class="vector-point" style="left: 15%; top: 20%; background: #4287f5;"></div>
                <div class="vector-label" style="left: 15%; top: 20%; color: #4287f5;">sink</div>
                
                <div class="vector-point" style="left: 20%; top: 25%; background: #4287f5;"></div>
                <div class="vector-label" style="left: 20%; top: 25%; color: #4287f5;">faucet</div>
                
                <div class="vector-point" style="left: 18%; top: 30%; background: #4287f5;"></div>
                <div class="vector-label" style="left: 18%; top: 30%; color: #4287f5;">kitchen</div>
                
                <!-- Appliances cluster -->
                <div class="vector-point" style="left: 45%; top: 60%; background: #f5a742;"></div>
                <div class="vector-label" style="left: 45%; top: 60%; color: #f5a742;">refrigerator</div>
                
                <div class="vector-point" style="left: 50%; top: 55%; background: #f5a742;"></div>
                <div class="vector-label" style="left: 50%; top: 55%; color: #f5a742;">oven</div>
                
                <div class="vector-point" style="left: 48%; top: 65%; background: #f5a742;"></div>
                <div class="vector-label" style="left: 48%; top: 65%; color: #f5a742;">microwave</div>
                
                <!-- Tools cluster -->
                <div class="vector-point" style="left: 75%; top: 30%; background: #dc3545;"></div>
                <div class="vector-label" style="left: 75%; top: 30%; color: #dc3545;">drill</div>
                
                <div class="vector-point" style="left: 80%; top: 25%; background: #dc3545;"></div>
                <div class="vector-label" style="left: 80%; top: 25%; color: #dc3545;">hammer</div>
                
                <div class="vector-point" style="left: 78%; top: 35%; background: #dc3545;"></div>
                <div class="vector-label" style="left: 78%; top: 35%; color: #dc3545;">saw</div>
                
                <!-- Query point -->
                <div class="vector-point" style="left: 22%; top: 28%; background: #28a745; width: 16px; height: 16px;"></div>
                <div class="vector-label" style="left: 22%; top: 28%; color: #28a745; font-weight: bold;">QUERY: "plumbing"</div>
            </div>
            <div class="highlight-box" style="margin-top: 20px;">
                <p><strong>Key Observation:</strong> Similar concepts cluster together. When searching for "plumbing," the system finds the nearest neighbors in vector space—in this case, kitchen/sink/faucet items rather than tools or appliances.</p>
            </div>
        </div>

        <!-- Quiz 2 -->
        <div class="slide">
            <h2>Knowledge Check 2</h2>
            <div class="quiz-container">
                <h3 style="margin-top: 0;">What is the main purpose of converting documents into vector embeddings?</h3>
                <div class="quiz-option" data-quiz="2" data-answer="b" data-option="a">
                    A) To compress files and save storage space
                </div>
                <div class="quiz-option" data-quiz="2" data-answer="b" data-option="b">
                    B) To enable mathematical comparison of document similarity
                </div>
                <div class="quiz-option" data-quiz="2" data-answer="b" data-option="c">
                    C) To encrypt sensitive business information
                </div>
                <div class="quiz-option" data-quiz="2" data-answer="b" data-option="d">
                    D) To make documents load faster in the LLM
                </div>
                <div class="quiz-feedback"></div>
            </div>
        </div>

        <!-- Slide 10: Measuring Similarity -->
        <div class="slide">
            <h2>Measuring Document Similarity</h2>
            <h3>Cosine Similarity: The Distance Metric</h3>
            <p>Once we have vector embeddings, we need to measure how similar they are. Cosine similarity is the standard approach:</p>
            <div class="highlight-box">
                <p style="font-family: monospace; font-size: 1.2em; text-align: center; margin: 20px 0;">
                    Similarity = (Vector1 · Vector2) / (||Vector1|| × ||Vector2||)
                </p>
                <p style="text-align: center;"><strong>Range:</strong> -1 (opposite) to +1 (identical)</p>
            </div>
            <h3>Practical Example</h3>
            <div style="background: #f9f9f9; padding: 20px; border-radius: 8px; margin: 20px 0;">
                <p><strong>Document A:</strong> "The TC-5000 router supports WiFi 6 and has excellent range."</p>
                <p><strong>Document B:</strong> "TC-5000 provides WiFi 6 connectivity with extended coverage."</p>
                <p><strong>Document C:</strong> "Our company picnic will be held in the park next Saturday."</p>
                <p style="margin-top: 20px; color: #DC143C;"><strong>Results:</strong></p>
                <p>Similarity(A, B) = 0.94 ← Very similar (same topic)</p>
                <p>Similarity(A, C) = 0.12 ← Not similar (different topics)</p>
            </div>
            <p><strong>Don't worry:</strong> Python libraries handle these calculations automatically. You just need to understand the concept.</p>
        </div>

        <!-- Slide 11: The RAG Architecture -->
        <div class="slide">
            <h2>Complete RAG System Architecture</h2>
            <div class="architecture-diagram">
                <div class="layer" style="background: #fff5f5;">
                    <h3 style="margin: 0;">User Interface Layer</h3>
                    <p style="margin: 10px 0;">User asks question: "How do I troubleshoot TC-5000 connectivity issues?"</p>
                </div>
                <div style="text-align: center; color: #DC143C; font-size: 1.5em;">↓</div>
                <div class="layer" style="background: #f0f8ff;">
                    <h3 style="margin: 0;">Embedding Layer (HuggingFace)</h3>
                    <p style="margin: 10px 0;">Converts question into vector: [2.3, 1.7, 4.2, ..., 8.9]</p>
                </div>
                <div style="text-align: center; color: #DC143C; font-size: 1.5em;">↓</div>
                <div class="layer" style="background: #f5fff5;">
                    <h3 style="margin: 0;">Vector Database (ChromaDB)</h3>
                    <p style="margin: 10px 0;">Searches for documents with similar vectors → Finds TC-5000 troubleshooting guide (similarity: 0.92)</p>
                </div>
                <div style="text-align: center; color: #DC143C; font-size: 1.5em;">↓</div>
                <div class="layer" style="background: #fffaf0;">
                    <h3 style="margin: 0;">Orchestration Layer (LangChain)</h3>
                    <p style="margin: 10px 0;">Combines: User question + Retrieved documents → Sends to LLM</p>
                </div>
                <div style="text-align: center; color: #DC143C; font-size: 1.5em;">↓</div>
                <div class="layer" style="background: #f9f0ff;">
                    <h3 style="margin: 0;">Generation Layer (LLM)</h3>
                    <p style="margin: 10px 0;">Reads context and generates: "According to the TC-5000 guide, try these steps..."</p>
                </div>
            </div>
        </div>

        <!-- Slide 12: The Three Key Components -->
        <div class="slide">
            <h2>RAG Technology Stack</h2>
            <div class="benefits-grid">
                <div class="benefit-card">
                    <h3>HuggingFace Embeddings</h3>
                    <p><strong>Purpose:</strong> Convert text to vectors</p>
                    <p><strong>Function:</strong> Provides pre-trained models that understand semantic meaning across multiple languages and domains</p>
                    <p><strong>Example:</strong> sentence-transformers/all-MiniLM-L6-v2</p>
                </div>
                <div class="benefit-card">
                    <h3>ChromaDB</h3>
                    <p><strong>Purpose:</strong> Store and search vectors</p>
                    <p><strong>Function:</strong> Specialized database optimized for finding similar vectors quickly, even with millions of documents</p>
                    <p><strong>Benefit:</strong> 100x faster than traditional databases for similarity search</p>
                </div>
                <div class="benefit-card">
                    <h3>LangChain</h3>
                    <p><strong>Purpose:</strong> Connect everything</p>
                    <p><strong>Function:</strong> Framework that orchestrates the entire workflow—from question to embedding to retrieval to generation</p>
                    <p><strong>Benefit:</strong> Write less code, focus on business logic</p>
                </div>
            </div>
            <div class="highlight-box" style="margin-top: 30px;">
                <h3>Why Three Separate Tools?</h3>
                <p>Each component is specialized and best-in-class. Using them together gives you flexibility to swap components as technology improves while maintaining the same overall architecture.</p>
            </div>
        </div>

        <!-- Quiz 3 -->
        <div class="slide">
            <h2>Knowledge Check 3</h2>
            <div class="quiz-container">
                <h3 style="margin-top: 0;">In a RAG system, what happens immediately AFTER the user asks a question?</h3>
                <div class="quiz-option" data-quiz="3" data-answer="c" data-option="a">
                    A) The LLM generates an answer directly
                </div>
                <div class="quiz-option" data-quiz="3" data-answer="c" data-option="b">
                    B) The system searches Google for information
                </div>
                <div class="quiz-option" data-quiz="3" data-answer="c" data-option="c">
                    C) The question is converted to a vector embedding
                </div>
                <div class="quiz-option" data-quiz="3" data-answer="c" data-option="d">
                    D) All documents are sent to the LLM
                </div>
                <div class="quiz-feedback"></div>
            </div>
        </div>

        <!-- Slide 13: Business Benefits of RAG -->
        <div class="slide">
            <h2>Business Benefits of RAG</h2>
            <div class="process-steps">
                <div class="process-step">
                    <h3>Accuracy and Trust</h3>
                    <p>RAG dramatically reduces hallucinations because responses are grounded in actual documents. Users can verify source citations.</p>
                    <p><strong>Metric:</strong> Studies show 85% reduction in factual errors compared to generic LLMs</p>
                </div>
                <div class="process-step">
                    <h3>Always Current</h3>
                    <p>Update documents in the database, and the LLM immediately has access to new information—no retraining required.</p>
                    <p><strong>Example:</strong> Add today's product release notes, answer questions about new features tomorrow</p>
                </div>
                <div class="process-step">
                    <h3>Cost-Effective</h3>
                    <p>No expensive model training. Use existing LLMs with your data. Typical implementation cost is 90% less than fine-tuning.</p>
                    <p><strong>Comparison:</strong> RAG setup: $1,000-5,000 | Fine-tuning: $50,000-200,000</p>
                </div>
                <div class="process-step">
                    <h3>Transparency</h3>
                    <p>Every answer can be traced to source documents. Critical for compliance, auditing, and building user confidence.</p>
                    <p><strong>Use case:</strong> Financial advice, medical information, legal guidance</p>
                </div>
            </div>
        </div>

        <!-- Slide 14: Real Business Applications -->
        <div class="slide">
            <h2>RAG Applications Across Industries</h2>
            <table class="comparison-table">
                <tr>
                    <th>Industry</th>
                    <th>Application</th>
                    <th>Business Impact</th>
                </tr>
                <tr>
                    <td><strong>Customer Support</strong></td>
                    <td>Instant access to product manuals, troubleshooting guides, and past support tickets</td>
                    <td>67% reduction in average handling time, 45% improvement in first-call resolution</td>
                </tr>
                <tr>
                    <td><strong>Legal Services</strong></td>
                    <td>Query case law, contracts, and regulations to support legal research</td>
                    <td>80% faster document review, 90% cost reduction in junior associate hours</td>
                </tr>
                <tr>
                    <td><strong>Healthcare</strong></td>
                    <td>Access medical literature, clinical guidelines, and patient history for decision support</td>
                    <td>35% improvement in diagnostic accuracy, 50% reduction in research time</td>
                </tr>
                <tr>
                    <td><strong>Finance</strong></td>
                    <td>Analyze company filings, market reports, and financial regulations</td>
                    <td>Real-time insights from 10,000+ documents, 70% faster compliance checks</td>
                </tr>
                <tr>
                    <td><strong>Human Resources</strong></td>
                    <td>Employee handbook, policies, benefits information instantly accessible</td>
                    <td>60% reduction in HR inquiry volume, 24/7 employee self-service</td>
                </tr>
            </table>
        </div>

        <!-- Slide 15: Introducing Fine-Tuning -->
        <div class="slide">
            <h2>Alternative Approach: Fine-Tuning</h2>
            <div class="highlight-box">
                <h3>What is Fine-Tuning?</h3>
                <p>Fine-tuning means continuing the training of a pre-trained LLM on your specific dataset. The model learns patterns, terminology, and style from your data.</p>
            </div>
            <h3>When Fine-Tuning Makes Sense</h3>
            <div class="benefits-grid" style="grid-template-columns: 1fr 1fr;">
                <div class="benefit-card">
                    <h3>✓ Good For:</h3>
                    <ul style="padding-left: 20px;">
                        <li>Specialized domain language (medical, legal, technical)</li>
                        <li>Consistent writing style (brand voice, tone)</li>
                        <li>Stable knowledge that rarely changes</li>
                        <li>When you have 10,000+ training examples</li>
                        <li>Need for very fast inference (no retrieval step)</li>
                    </ul>
                </div>
                <div class="benefit-card">
                    <h3>✗ Challenges:</h3>
                    <ul style="padding-left: 20px;">
                        <li>Expensive (requires GPU compute for training)</li>
                        <li>Time-consuming (days to weeks for training)</li>
                        <li>Requires large datasets (thousands of examples)</li>
                        <li>Difficult to update (need to retrain)</li>
                        <li>Risk of "catastrophic forgetting" (model forgets original training)</li>
                    </ul>
                </div>
            </div>
        </div>

        <!-- Slide 16: RAG vs Fine-Tuning Comparison -->
        <div class="slide">
            <h2>RAG vs. Fine-Tuning: Decision Framework</h2>
            <table class="comparison-table">
                <tr>
                    <th>Factor</th>
                    <th>RAG</th>
                    <th>Fine-Tuning</th>
                </tr>
                <tr>
                    <td><strong>Setup Time</strong></td>
                    <td>Hours to days</td>
                    <td>Weeks to months</td>
                </tr>
                <tr>
                    <td><strong>Setup Cost</strong></td>
                    <td>$1,000 - $5,000</td>
                    <td>$50,000 - $200,000</td>
                </tr>
                <tr>
                    <td><strong>Data Required</strong></td>
                    <td>Any amount (even 10 docs)</td>
                    <td>10,000+ training examples</td>
                </tr>
                <tr>
                    <td><strong>Update Frequency</strong></td>
                    <td>Real-time (just add docs)</td>
                    <td>Requires full retraining</td>
                </tr>
                <tr>
                    <td><strong>Transparency</strong></td>
                    <td>High (shows sources)</td>
                    <td>Low (black box)</td>
                </tr>
                <tr>
                    <td><strong>Response Speed</strong></td>
                    <td>Slower (retrieval + generation)</td>
                    <td>Faster (just generation)</td>
                </tr>
                <tr>
                    <td><strong>Best Use Case</strong></td>
                    <td>Dynamic knowledge bases, customer support, research</td>
                    <td>Specialized domains, consistent style, stable knowledge</td>
                </tr>
            </table>
            <div class="highlight-box" style="margin-top: 20px;">
                <p><strong>Recommended Strategy:</strong> Start with RAG. It's faster, cheaper, and more flexible. Consider fine-tuning only when you have specific style/domain requirements and substantial training data.</p>
            </div>
        </div>

        <!-- Quiz 4 -->
        <div class="slide">
            <h2>Knowledge Check 4</h2>
            <div class="quiz-container">
                <h3 style="margin-top: 0;">A company updates its product catalog weekly and needs an AI assistant to answer customer questions about products. Which approach is most suitable?</h3>
                <div class="quiz-option" data-quiz="4" data-answer="a" data-option="a">
                    A) RAG—because the information changes frequently and needs to stay current
                </div>
                <div class="quiz-option" data-quiz="4" data-answer="a" data-option="b">
                    B) Fine-tuning—because it provides faster responses
                </div>
                <div class="quiz-option" data-quiz="4" data-answer="a" data-option="c">
                    C) Neither—just use ChatGPT directly
                </div>
                <div class="quiz-option" data-quiz="4" data-answer="a" data-option="d">
                    D) Both—always use RAG and fine-tuning together
                </div>
                <div class="quiz-feedback"></div>
            </div>
        </div>

        <!-- Slide 17: Implementation Workflow -->
        <div class="slide">
            <h2>Building a RAG System: Step-by-Step</h2>
            <div class="process-steps">
                <div class="process-step">
                    <h3>Prepare Your Documents</h3>
                    <p>Collect and organize your company's documents. Clean the data (remove duplicates, fix formatting, remove sensitive information).</p>
                    <p><strong>Tip:</strong> Start with 50-100 documents to test the system before scaling up.</p>
                </div>
                <div class="process-step">
                    <h3>Install Required Tools</h3>
                    <p>Set up Python environment with LangChain, ChromaDB, and HuggingFace libraries.</p>
                    <div class="code-preview" style="margin-top: 10px;">
pip install langchain chromadb sentence-transformers
                    </div>
                </div>
                <div class="process-step">
                    <h3>Create Embeddings</h3>
                    <p>Convert each document into vector embeddings using HuggingFace models.</p>
                    <div class="code-preview" style="margin-top: 10px;">
embeddings = HuggingFaceEmbeddings(
    model_name="all-MiniLM-L6-v2"
)
                    </div>
                </div>
                <div class="process-step">
                    <h3>Store in Vector Database</h3>
                    <p>Load embeddings into ChromaDB for efficient similarity search.</p>
                    <div class="code-preview" style="margin-top: 10px;">
vectorstore = Chroma.from_documents(
    documents=docs,
    embedding=embeddings
)
                    </div>
                </div>
                <div class="process-step">
                    <h3>Build Query Interface</h3>
                    <p>Use LangChain to connect the retrieval system to your LLM, creating a complete question-answering pipeline.</p>
                </div>
            </div>
        </div>

        <!-- Slide 18: Code Walkthrough Preview -->
        <div class="slide">
            <h2>Today's Hands-On Activity</h2>
            <h3>What You'll Build</h3>
            <p>A working RAG system that can answer questions about a set of sample documents. You'll see how each component works together.</p>
            <div class="benefits-grid" style="grid-template-columns: 1fr 1fr;">
                <div class="benefit-card">
                    <h3>Part 1: Simple RAG</h3>
                    <p><strong>File:</strong> DATA5000_Simple_RAG.ipynb</p>
                    <p><strong>What you'll do:</strong></p>
                    <ul style="padding-left: 20px; margin-top: 10px;">
                        <li>Create sample documents</li>
                        <li>Initialize embedding model</li>
                        <li>Build ChromaDB vector store</li>
                        <li>Query the database</li>
                        <li>Add metadata and filters</li>
                    </ul>
                    <p style="margin-top: 10px;"><strong>Time:</strong> 20-25 minutes</p>
                </div>
                <div class="benefit-card">
                    <h3>Part 2: Cosine Similarity</h3>
                    <p><strong>File:</strong> DATA5000_Cosine_similarity.ipynb</p>
                    <p><strong>What you'll do:</strong></p>
                    <ul style="padding-left: 20px; margin-top: 10px;">
                        <li>See word embeddings in action</li>
                        <li>Calculate similarity scores</li>
                        <li>Understand why similar concepts cluster</li>
                        <li>Experiment with different words</li>
                    </ul>
                    <p style="margin-top: 10px;"><strong>Time:</strong> 15 minutes</p>
                </div>
            </div>
            <div class="highlight-box" style="margin-top: 20px;">
                <p><strong>Learning Goal:</strong> By the end of the activities, you should understand how to connect your own company documents to an LLM and see why vector embeddings enable semantic search.</p>
            </div>
        </div>

        <!-- Slide 19: Real Business Scenario -->
        <div class="slide">
            <h2>Case Study: TechCorp Implementation</h2>
            <h3>Background</h3>
            <p>TechCorp's customer support team handles 1,000 emails daily about 500+ products. Agents spend 40% of their time searching for information in 10 years of documentation.</p>
            <div class="process-steps" style="margin-top: 30px;">
                <div class="process-step">
                    <h3>Initial Situation</h3>
                    <p><strong>Challenge:</strong> Average response time of 4 hours, inconsistent answers, high agent frustration</p>
                    <p><strong>Cost:</strong> $2.5M annually in support costs</p>
                </div>
                <div class="process-step">
                    <h3>RAG Implementation (6 weeks)</h3>
                    <p><strong>Data:</strong> Ingested 10,000 documents (product manuals, FAQs, past tickets, troubleshooting guides)</p>
                    <p><strong>System:</strong> Built RAG interface integrated with email system</p>
                    <p><strong>Cost:</strong> $25,000 setup + $500/month hosting</p>
                </div>
                <div class="process-step">
                    <h3>Results After 6 Months</h3>
                    <p>✓ Average response time: 45 minutes (89% reduction)</p>
                    <p>✓ First-response accuracy: 92% (up from 67%)</p>
                    <p>✓ Agent satisfaction: +45 points</p>
                    <p>✓ Cost savings: $1.2M annually</p>
                    <p><strong>ROI:</strong> 4,700% in first year</p>
                </div>
            </div>
        </div>

        <!-- Slide 20: Combining RAG and Fine-Tuning -->
        <div class="slide">
            <h2>Advanced: Combining RAG and Fine-Tuning</h2>
            <p>For maximum performance, some organizations use both approaches together:</p>
            <div class="comparison-box" style="margin: 30px 0;">
                <div class="box">
                    <h3>RAG Handles:</h3>
                    <ul style="padding-left: 20px;">
                        <li>Accessing current information</li>
                        <li>Retrieving specific facts</li>
                        <li>Providing source citations</li>
                        <li>Updating knowledge in real-time</li>
                    </ul>
                </div>
                <div class="box">
                    <h3>Fine-Tuning Handles:</h3>
                    <ul style="padding-left: 20px;">
                        <li>Domain-specific language</li>
                        <li>Company writing style</li>
                        <li>Common question patterns</li>
                        <li>Technical terminology</li>
                    </ul>
                </div>
            </div>
            <div class="highlight-box">
                <h3>Example: Legal Firm Implementation</h3>
                <p><strong>Fine-tuned model:</strong> Trained on legal writing style, case law structure, and legal reasoning patterns</p>
                <p><strong>RAG system:</strong> Accesses current case database, recent rulings, and client-specific documents</p>
                <p><strong>Result:</strong> Natural legal writing (from fine-tuning) with accurate, current case citations (from RAG)</p>
            </div>
            <p style="margin-top: 20px;"><strong>Cost consideration:</strong> This approach costs $150,000-300,000 to implement but provides best-in-class performance for mission-critical applications.</p>
        </div>

        <!-- Quiz 5 -->
        <div class="slide">
            <h2>Knowledge Check 5</h2>
            <div class="quiz-container">
                <h3 style="margin-top: 0;">Which statement about RAG implementation is most accurate?</h3>
                <div class="quiz-option" data-quiz="5" data-answer="c" data-option="a">
                    A) RAG requires retraining the entire LLM on your documents
                </div>
                <div class="quiz-option" data-quiz="5" data-answer="c" data-option="b">
                    B) Once implemented, RAG systems cannot be updated with new information
                </div>
                <div class="quiz-option" data-quiz="5" data-answer="c" data-option="c">
                    C) RAG provides transparency by showing which documents were used to generate answers
                </div>
                <div class="quiz-option" data-quiz="5" data-answer="c" data-option="d">
                    D) RAG is always more expensive than fine-tuning
                </div>
                <div class="quiz-feedback"></div>
            </div>
        </div>

        <!-- Slide 21: Success Factors -->
        <div class="slide">
            <h2>Critical Success Factors for RAG</h2>
            <h3>What makes RAG implementations succeed or fail?</h3>
            <table class="comparison-table">
                <tr>
                    <th>Factor</th>
                    <th>Success Pattern</th>
                    <th>Failure Pattern</th>
                </tr>
                <tr>
                    <td><strong>Document Quality</strong></td>
                    <td>Clean, well-organized, accurate source documents with clear structure</td>
                    <td>Poorly formatted, outdated, or contradictory documents that confuse the system</td>
                </tr>
                <tr>
                    <td><strong>Chunk Size</strong></td>
                    <td>Optimal: 200-500 words per chunk. Balances context and precision.</td>
                    <td>Too small (fragments sentences) or too large (retrieves irrelevant content)</td>
                </tr>
                <tr>
                    <td><strong>Metadata Strategy</strong></td>
                    <td>Rich metadata (date, author, department, document type) enables filtering</td>
                    <td>No metadata means retrieving potentially outdated or irrelevant documents</td>
                </tr>
                <tr>
                    <td><strong>Monitoring</strong></td>
                    <td>Track answer quality, user feedback, retrieval accuracy—iterate constantly</td>
                    <td>"Set and forget"—quality degrades as new docs are added without review</td>
                </tr>
                <tr>
                    <td><strong>User Training</strong></td>
                    <td>Teach users how to ask good questions and interpret citations</td>
                    <td>Users don't trust system because they don't understand how it works</td>
                </tr>
            </table>
        </div>

        <!-- Slide 22: Looking Ahead -->
        <div class="slide">
            <h2>Connection to Assessment 3</h2>
            <div class="highlight-box">
                <h3>How This Week Relates to Your Project</h3>
                <p>Assessment 3 requires you to develop a data-driven business recommendation. RAG and fine-tuning are powerful tools you can use:</p>
            </div>
            <div class="benefits-grid" style="margin: 30px 0;">
                <div class="benefit-card">
                    <h3>Potential Application 1</h3>
                    <p><strong>Build a RAG system</strong> using your business case documents, market research, and industry reports to support your analysis and recommendations.</p>
                    <p style="margin-top: 10px; color: #DC143C;">Shows prescriptive analytics capability</p>
                </div>
                <div class="benefit-card">
                    <h3>Potential Application 2</h3>
                    <p><strong>Create a custom knowledge base</strong> that executives can query to understand your recommendations and supporting evidence.</p>
                    <p style="margin-top: 10px; color: #DC143C;">Demonstrates business value</p>
                </div>
                <div class="benefit-card">
                    <h3>Potential Application 3</h3>
                    <p><strong>Use RAG to analyze</strong> competitor strategies, customer feedback, or market trends specific to your business case.</p>
                    <p style="margin-top: 10px; color: #DC143C;">Provides data-driven insights</p>
                </div>
            </div>
            <p><strong>Next week (Week 12):</strong> We'll explore advanced LLM applications including agents, tool use, and more sophisticated RAG implementations that you can leverage in your assessments.</p>
        </div>

        <!-- Slide 23: Key Takeaways -->
        <div class="slide">
            <h2>Key Takeaways</h2>
            <div class="process-steps">
                <div class="process-step">
                    <h3>The Problem</h3>
                    <p>Generic LLMs don't have access to your company's specific data, leading to vague or incorrect answers.</p>
                </div>
                <div class="process-step">
                    <h3>The Solution: RAG</h3>
                    <p>Retrieval-Augmented Generation gives LLMs access to relevant documents in real-time, grounding responses in actual information.</p>
                </div>
                <div class="process-step">
                    <h3>How It Works</h3>
                    <p>Convert documents to vector embeddings → Store in specialized database → Retrieve similar documents when users ask questions → LLM generates informed answer.</p>
                </div>
                <div class="process-step">
                    <h3>Key Components</h3>
                    <p>HuggingFace (embeddings), ChromaDB (vector storage), LangChain (orchestration), LLM (generation).</p>
                </div>
                <div class="process-step">
                    <h3>Business Impact</h3>
                    <p>85% reduction in factual errors, 60-90% faster response times, 90% lower cost than fine-tuning, always current information.</p>
                </div>
                <div class="process-step">
                    <h3>When to Use What</h3>
                    <p>RAG: Dynamic information, need sources, fast implementation. Fine-tuning: Stable domain, style requirements, large training data. Both: Maximum performance for critical applications.</p>
                </div>
            </div>
        </div>

        <!-- Slide 24: Additional Resources -->
        <div class="slide">
            <h2>Resources for Further Learning</h2>
            <div class="benefits-grid" style="grid-template-columns: 1fr 1fr;">
                <div class="benefit-card">
                    <h3>Documentation</h3>
                    <ul style="padding-left: 20px;">
                        <li>LangChain RAG Tutorial: docs.langchain.com/rag</li>
                        <li>ChromaDB Quickstart: docs.trychroma.com</li>
                        <li>HuggingFace Embeddings: huggingface.co/sentence-transformers</li>
                    </ul>
                </div>
                <div class="benefit-card">
                    <h3>Research Papers</h3>
                    <ul style="padding-left: 20px;">
                        <li>"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks" (Lewis et al., 2020)</li>
                        <li>"A Taxonomy of Retrieval-Augmented Generation" (2024)</li>
                    </ul>
                </div>
                <div class="benefit-card">
                    <h3>Video Resources</h3>
                    <ul style="padding-left: 20px;">
                        <li>RAG Explained: youtube.com/watch?v=tKPSmn-urB4</li>
                        <li>Building Production RAG Systems</li>
                        <li>Vector Databases Deep Dive</li>
                    </ul>
                </div>
                <div class="benefit-card">
                    <h3>Tools & Templates</h3>
                    <ul style="padding-left: 20px;">
                        <li>Google Colab notebooks (provided)</li>
                        <li>RAG decision framework</li>
                        <li>Assessment 3 application guide</li>
                    </ul>
                </div>
            </div>
        </div>

        <!-- Slide 25: Next Steps -->
        <div class="slide">
            <h2>What Happens Next</h2>
            <div class="highlight-box">
                <h3>Today's Activities</h3>
                <p>Complete the two Google Colab notebooks to gain hands-on experience with vector embeddings and RAG systems.</p>
            </div>
            <div class="process-steps" style="margin-top: 30px;">
                <div class="process-step">
                    <h3>Activity 1: Cosine Similarity</h3>
                    <p>File: DATA5000_Cosine_similarity.ipynb</p>
                    <p>See how word embeddings capture semantic meaning and calculate similarity scores between different words.</p>
                </div>
                <div class="process-step">
                    <h3>Activity 2: Build a Simple RAG System</h3>
                    <p>File: DATA5000_Simple_RAG.ipynb</p>
                    <p>Create a complete RAG pipeline with document embeddings, vector storage, and querying capabilities.</p>
                </div>
                <div class="process-step">
                    <h3>Week 12 Preview</h3>
                    <p>Next week we'll explore advanced LLM applications: agents that can use tools, more sophisticated RAG architectures, and multi-step reasoning systems.</p>
                </div>
            </div>
            <p style="margin-top: 30px; font-size: 1.3em; color: #DC143C;"><strong>Remember:</strong> The goal isn't to memorize syntax—it's to understand how these systems work so you can apply them to real business problems.</p>
        </div>

        <!-- Final Slide -->
        <div class="slide">
            <h1>Thank You</h1>
            <div style="margin-top: 60px;">
                <h2>Questions?</h2>
                <p class="subtitle">Let's discuss how RAG can solve real business challenges</p>
            </div>
            <div style="margin-top: auto;">
                <p style="font-size: 1.1em; color: #666;">Kaplan Business School</p>
                <p style="font-size: 1em; color: #999;">DATA5000 - Week 11</p>
            </div>
        </div>
    </div>

    <div class="slide-number">
        <span id="current-slide">1</span> / <span id="total-slides">25</span>
    </div>

    <div class="navigation">
        <button id="prev-btn" onclick="previousSlide()">← Previous</button>
        <button id="next-btn" onclick="nextSlide()">Next →</button>
    </div>

    <div class="kbs-logo">
        KAPLAN BUSINESS SCHOOL AUSTRALIA
    </div>

    <script>
        let currentSlide = 0;
        const slides = document.querySelectorAll('.slide');
        const totalSlides = slides.length;
        const quizAnswers = {};

        document.getElementById('total-slides').textContent = totalSlides;

        function showSlide(n) {
            slides[currentSlide].classList.remove('active');
            currentSlide = (n + totalSlides) % totalSlides;
            slides[currentSlide].classList.add('active');
            document.getElementById('current-slide').textContent = currentSlide + 1;
            
            document.getElementById('prev-btn').disabled = currentSlide === 0;
            document.getElementById('next-btn').disabled = currentSlide === totalSlides - 1;
        }

        function nextSlide() {
            showSlide(currentSlide + 1);
        }

        function previousSlide() {
            showSlide(currentSlide - 1);
        }

        // Keyboard navigation
        document.addEventListener('keydown', (e) => {
            if (e.key === 'ArrowRight') nextSlide();
            if (e.key === 'ArrowLeft') previousSlide();
        });

        // Quiz functionality
        document.querySelectorAll('.quiz-option').forEach(option => {
            option.addEventListener('click', function() {
                const quizNum = this.getAttribute('data-quiz');
                const selectedOption = this.getAttribute('data-option');
                const correctAnswer = this.getAttribute('data-answer');
                const feedback = this.parentElement.querySelector('.quiz-feedback');
                
                // Remove previous selections
                this.parentElement.querySelectorAll('.quiz-option').forEach(opt => {
                    opt.classList.remove('selected', 'correct', 'incorrect');
                });
                
                // Mark this option
                this.classList.add('selected');
                
                // Show feedback
                if (selectedOption === correctAnswer) {
                    this.classList.add('correct');
                    feedback.className = 'quiz-feedback correct show';
                    feedback.textContent = '✓ Correct! ' + getQuizExplanation(quizNum, correctAnswer);
                } else {
                    this.classList.add('incorrect');
                    feedback.className = 'quiz-feedback incorrect show';
                    feedback.textContent = '✗ Not quite. ' + getQuizExplanation(quizNum, correctAnswer);
                }
                
                quizAnswers[quizNum] = selectedOption;
            });
        });

        function getQuizExplanation(quizNum, correctAnswer) {
            const explanations = {
                '1': {
                    'c': "ChatGPT's training doesn't include your company's internal documents, customer data, or proprietary information. RAG and fine-tuning bridge this gap by giving the LLM access to your specific data."
                },
                '2': {
                    'b': "Vector embeddings convert text into numerical representations that preserve semantic meaning. This allows computers to mathematically measure how similar two documents are, enabling efficient similarity search across large document collections."
                },
                '3': {
                    'c': "The first step in RAG is converting the user's question into a vector embedding. This allows the system to find documents with similar embeddings (i.e., similar meaning) in the vector database. Only after retrieving relevant documents does the LLM generate an answer."
                },
                '4': {
                    'a': "Because the product catalog changes weekly, RAG is ideal—you can simply add new product documents to the database without any retraining. Fine-tuning would require expensive retraining every week to stay current."
                },
                '5': {
                    'c': "One of RAG's key advantages is transparency. The system can show exactly which documents were used to generate each answer, allowing users to verify information and trace sources. This is critical for building trust and ensuring accountability."
                }
            };
            
            return explanations[quizNum][correctAnswer] || "Review the concepts covered in the slides.";
        }

        // Initialize
        showSlide(0);
    </script>
</body>
</html>