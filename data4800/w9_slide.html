<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Week 9: Natural Language Processing and Generative AI</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif;
            background: white;
            color: #333;
            overflow-x: hidden;
        }

        .slide {
            min-height: 100vh;
            padding: 60px 80px;
            display: none;
            flex-direction: column;
            justify-content: center;
            position: relative;
        }

        .slide.active {
            display: flex;
            animation: slideIn 0.5s ease-out;
        }

        @keyframes slideIn {
            from {
                opacity: 0;
                transform: translateX(50px);
            }
            to {
                opacity: 1;
                transform: translateX(0);
            }
        }

        h1, h2 {
            color: #C41E3A;
            margin-bottom: 30px;
        }

        h1 {
            font-size: 2.8em;
            font-weight: 700;
            letter-spacing: -1px;
        }

        h2 {
            font-size: 2.2em;
            font-weight: 600;
        }

        h3 {
            color: #C41E3A;
            font-size: 1.6em;
            margin-top: 30px;
            margin-bottom: 15px;
        }

        p, li {
            font-size: 1.3em;
            line-height: 1.8;
            margin-bottom: 15px;
        }

        ul {
            margin-left: 40px;
        }

        .subtitle {
            font-size: 1.5em;
            color: #666;
            margin-top: -20px;
            margin-bottom: 40px;
        }

        .navigation {
            position: fixed;
            bottom: 30px;
            right: 30px;
            display: flex;
            gap: 15px;
            z-index: 1000;
        }

        .nav-btn {
            background: #C41E3A;
            color: white;
            border: none;
            padding: 12px 25px;
            font-size: 1em;
            cursor: pointer;
            border-radius: 5px;
            transition: background 0.3s;
        }

        .nav-btn:hover {
            background: #9a1829;
        }

        .nav-btn:disabled {
            background: #ccc;
            cursor: not-allowed;
        }

        .slide-counter {
            position: fixed;
            top: 30px;
            right: 30px;
            font-size: 1.1em;
            color: #666;
            z-index: 1000;
        }

        .progress-bar {
            position: fixed;
            top: 0;
            left: 0;
            height: 4px;
            background: #C41E3A;
            transition: width 0.3s;
            z-index: 1000;
        }

        /* Visualization Containers */
        .viz-container {
            margin: 30px 0;
            padding: 30px;
            background: #f8f8f8;
            border-radius: 8px;
            border-left: 4px solid #C41E3A;
        }

        /* Timeline Visualization */
        .timeline {
            position: relative;
            margin: 40px 0;
        }

        .timeline-item {
            display: flex;
            margin-bottom: 30px;
            align-items: center;
        }

        .timeline-year {
            font-size: 1.4em;
            font-weight: bold;
            color: #C41E3A;
            width: 120px;
            flex-shrink: 0;
        }

        .timeline-content {
            flex: 1;
            padding: 20px;
            background: #f8f8f8;
            border-radius: 5px;
            border-left: 3px solid #C41E3A;
        }

        .timeline-content h4 {
            color: #C41E3A;
            margin-bottom: 10px;
        }

        /* Process Flow */
        .process-flow {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin: 40px 0;
            flex-wrap: wrap;
        }

        .process-step {
            flex: 1;
            min-width: 150px;
            text-align: center;
            padding: 20px;
            background: #f8f8f8;
            border-radius: 8px;
            margin: 10px;
            border-top: 3px solid #C41E3A;
        }

        .process-step h4 {
            color: #C41E3A;
            margin-bottom: 10px;
            font-size: 1.2em;
        }

        .arrow {
            font-size: 2em;
            color: #C41E3A;
            margin: 0 10px;
        }

        /* Comparison Table */
        .comparison-table {
            margin: 30px 0;
            border-collapse: collapse;
            width: 100%;
        }

        .comparison-table th {
            background: #C41E3A;
            color: white;
            padding: 15px;
            text-align: left;
            font-size: 1.2em;
        }

        .comparison-table td {
            padding: 15px;
            border-bottom: 1px solid #ddd;
            font-size: 1.1em;
        }

        .comparison-table tr:nth-child(even) {
            background: #f8f8f8;
        }

        /* Quiz Styles */
        .quiz-container {
            background: #f8f8f8;
            padding: 40px;
            border-radius: 8px;
            margin: 30px 0;
            border-left: 4px solid #C41E3A;
        }

        .quiz-question {
            font-size: 1.4em;
            font-weight: 600;
            margin-bottom: 25px;
            color: #C41E3A;
        }

        .quiz-options {
            display: flex;
            flex-direction: column;
            gap: 15px;
        }

        .quiz-option {
            padding: 15px 20px;
            background: white;
            border: 2px solid #ddd;
            border-radius: 5px;
            cursor: pointer;
            transition: all 0.3s;
            font-size: 1.1em;
        }

        .quiz-option:hover {
            border-color: #C41E3A;
            background: #fff5f5;
        }

        .quiz-option.selected {
            border-color: #C41E3A;
            background: #fff5f5;
        }

        .quiz-option.correct {
            border-color: #27ae60;
            background: #d4edda;
        }

        .quiz-option.incorrect {
            border-color: #e74c3c;
            background: #f8d7da;
        }

        .quiz-feedback {
            margin-top: 20px;
            padding: 15px;
            border-radius: 5px;
            font-size: 1.1em;
            display: none;
        }

        .quiz-feedback.show {
            display: block;
        }

        .quiz-feedback.correct {
            background: #d4edda;
            color: #155724;
            border-left: 4px solid #27ae60;
        }

        .quiz-feedback.incorrect {
            background: #f8d7da;
            color: #721c24;
            border-left: 4px solid #e74c3c;
        }

        /* Data Visualization */
        .stat-box {
            display: inline-block;
            padding: 20px 30px;
            background: #f8f8f8;
            border-radius: 8px;
            margin: 15px;
            border-top: 3px solid #C41E3A;
        }

        .stat-number {
            font-size: 2.5em;
            font-weight: bold;
            color: #C41E3A;
            display: block;
        }

        .stat-label {
            font-size: 1.1em;
            color: #666;
            margin-top: 5px;
        }

        /* Example Box */
        .example-box {
            background: #f8f8f8;
            padding: 25px;
            border-radius: 8px;
            margin: 20px 0;
            border-left: 4px solid #C41E3A;
        }

        .example-box h4 {
            color: #C41E3A;
            margin-bottom: 15px;
        }

        /* Code Display */
        .code-display {
            background: #2d2d2d;
            color: #f8f8f8;
            padding: 20px;
            border-radius: 5px;
            font-family: 'Courier New', monospace;
            overflow-x: auto;
            margin: 20px 0;
        }

        /* Architecture Diagram */
        .architecture {
            display: flex;
            justify-content: center;
            align-items: center;
            margin: 40px 0;
        }

        .arch-box {
            padding: 20px 30px;
            background: #f8f8f8;
            border: 2px solid #C41E3A;
            border-radius: 8px;
            margin: 0 15px;
            text-align: center;
            min-width: 150px;
        }

        .arch-box h4 {
            color: #C41E3A;
            margin-bottom: 10px;
        }

        /* Highlight Box */
        .highlight {
            background: #fff5f5;
            padding: 20px;
            border-radius: 5px;
            border-left: 4px solid #C41E3A;
            margin: 20px 0;
            font-size: 1.2em;
        }

        .two-column {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 40px;
            margin: 30px 0;
        }

        /* Bar Chart */
        .bar-chart {
            margin: 30px 0;
        }

        .bar-item {
            margin-bottom: 20px;
        }

        .bar-label {
            font-size: 1.1em;
            margin-bottom: 8px;
            color: #333;
        }

        .bar {
            height: 30px;
            background: linear-gradient(to right, #C41E3A, #e74c3c);
            border-radius: 3px;
            position: relative;
            animation: growBar 1s ease-out;
        }

        @keyframes growBar {
            from { width: 0; }
        }

        .bar-value {
            position: absolute;
            right: 10px;
            top: 50%;
            transform: translateY(-50%);
            color: white;
            font-weight: bold;
        }

        /* Responsive Design */
        @media (max-width: 768px) {
            .slide {
                padding: 40px 30px;
            }
            
            h1 {
                font-size: 2em;
            }
            
            h2 {
                font-size: 1.6em;
            }
            
            .two-column {
                grid-template-columns: 1fr;
            }
            
            .process-flow {
                flex-direction: column;
            }
            
            .arrow {
                transform: rotate(90deg);
            }
        }
    </style>
</head>
<body>
    <div class="progress-bar" id="progressBar"></div>
    <div class="slide-counter" id="slideCounter">1 / 34</div>

    <!-- Slide 1: Title -->
    <div class="slide active">
        <h1>Natural Language Processing and Generative AI</h1>
        <p class="subtitle">DATA4800 - Workshop 9</p>
        <div style="margin-top: 50px;">
            <p style="font-size: 1.4em; color: #666;">Understanding how machines process and generate human language</p>
        </div>
    </div>

    <!-- Slide 2: Learning Outcomes -->
    <div class="slide">
        <h2>Workshop Learning Outcomes</h2>
        <div class="viz-container">
            <div style="display: flex; flex-direction: column; gap: 25px;">
                <div style="display: flex; align-items: start;">
                    <span style="color: #C41E3A; font-size: 2em; margin-right: 20px; font-weight: bold;">1</span>
                    <div>
                        <h3 style="margin-top: 0;">Explore Traditional NLP and Machine Learning</h3>
                        <p>Understand text pre-processing, classification techniques, and the Naïve Bayes algorithm</p>
                    </div>
                </div>
                <div style="display: flex; align-items: start;">
                    <span style="color: #C41E3A; font-size: 2em; margin-right: 20px; font-weight: bold;">2</span>
                    <div>
                        <h3 style="margin-top: 0;">Explore Large Language Models and Business Applications</h3>
                        <p>Discover transformers, GPT evolution, and real-world use cases in business contexts</p>
                    </div>
                </div>
                <div style="display: flex; align-items: start;">
                    <span style="color: #C41E3A; font-size: 2em; margin-right: 20px; font-weight: bold;">3</span>
                    <div>
                        <h3 style="margin-top: 0;">Understand Ethical Considerations</h3>
                        <p>Examine responsible use of LLMs in academic and professional environments</p>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- Slide 3: Business Challenge -->
    <div class="slide">
        <h2>The Business Challenge</h2>
        <div class="highlight">
            <h3 style="margin-top: 0;">Scenario: E-commerce Customer Feedback Analysis</h3>
            <p>Your online retail company receives 10,000 customer reviews daily across multiple platforms</p>
        </div>
        
        <div class="two-column" style="margin-top: 40px;">
            <div>
                <h3>The Problem</h3>
                <ul>
                    <li>Manual review reading is impossible at scale</li>
                    <li>Response time directly impacts customer satisfaction</li>
                    <li>Competitive advantage requires real-time insights</li>
                    <li>Negative reviews need immediate attention</li>
                </ul>
            </div>
            <div>
                <h3>Business Impact</h3>
                <div class="stat-box">
                    <span class="stat-number">10,000</span>
                    <span class="stat-label">Daily reviews</span>
                </div>
                <div class="stat-box">
                    <span class="stat-number">24h</span>
                    <span class="stat-label">Manual processing time</span>
                </div>
                <div class="stat-box">
                    <span class="stat-number">$2M</span>
                    <span class="stat-label">Annual manual cost</span>
                </div>
            </div>
        </div>
    </div>

    <!-- Slide 4: Two Approaches -->
    <div class="slide">
        <h2>Two Approaches to Text Analysis</h2>
        <div class="timeline">
            <div class="timeline-item">
                <div class="timeline-year">2000-2015</div>
                <div class="timeline-content">
                    <h4>Traditional NLP + Machine Learning</h4>
                    <p><strong>Approach:</strong> Feature engineering, statistical models, rule-based systems</p>
                    <p><strong>Example:</strong> Naïve Bayes classifier, Bag-of-Words</p>
                    <p><strong>Characteristics:</strong> Requires labeled data, explainable, limited context understanding</p>
                </div>
            </div>
            <div class="timeline-item">
                <div class="timeline-year">2017-2025</div>
                <div class="timeline-content">
                    <h4>Modern Large Language Models</h4>
                    <p><strong>Approach:</strong> Deep learning, transformer architecture, pre-trained models</p>
                    <p><strong>Example:</strong> GPT-4, ChatGPT, Claude</p>
                    <p><strong>Characteristics:</strong> Context-aware, minimal training, human-like understanding</p>
                </div>
            </div>
        </div>
        
        <div class="highlight">
            <p><strong>Today's Journey:</strong> We will explore both approaches to understand when and why to use each method</p>
        </div>
    </div>

    <!-- Slide 5: What is NLP -->
    <div class="slide">
        <h2>What is Natural Language Processing?</h2>
        <p>Natural Language Processing (NLP) is a field of artificial intelligence that enables computers to understand, interpret, and generate human language.</p>
        
        <h3>Key Challenges in NLP</h3>
        <div class="two-column">
            <div class="example-box">
                <h4>Ambiguity</h4>
                <p>"I saw a man with a telescope"</p>
                <p style="font-size: 0.95em; color: #666;">Did I use a telescope to see him? Or did he have a telescope?</p>
            </div>
            <div class="example-box">
                <h4>Context Dependency</h4>
                <p>"The bank is closed"</p>
                <p style="font-size: 0.95em; color: #666;">Financial institution or river bank?</p>
            </div>
        </div>
        
        <div class="two-column">
            <div class="example-box">
                <h4>Sarcasm and Irony</h4>
                <p>"Great! Another meeting..."</p>
                <p style="font-size: 0.95em; color: #666;">Positive words, negative sentiment</p>
            </div>
            <div class="example-box">
                <h4>Multiple Meanings</h4>
                <p>"Book" as a noun vs. verb</p>
                <p style="font-size: 0.95em; color: #666;">"Read this book" vs. "Book a flight"</p>
            </div>
        </div>
    </div>

    <!-- Slide 6: NLP Applications -->
    <div class="slide">
        <h2>Business Applications of NLP</h2>
        <div class="process-flow">
            <div class="process-step">
                <h4>Customer Service</h4>
                <p>Chatbots, automated support, sentiment analysis</p>
            </div>
            <span class="arrow">→</span>
            <div class="process-step">
                <h4>Content Analysis</h4>
                <p>Document classification, information extraction</p>
            </div>
            <span class="arrow">→</span>
            <div class="process-step">
                <h4>Translation</h4>
                <p>Multi-language support, localization</p>
            </div>
        </div>
        
        <h3 style="margin-top: 50px;">Industry Statistics</h3>
        <div class="bar-chart">
            <div class="bar-item">
                <div class="bar-label">Customer Service Automation</div>
                <div class="bar" style="width: 85%;">
                    <span class="bar-value">85% adoption</span>
                </div>
            </div>
            <div class="bar-item">
                <div class="bar-label">Sentiment Analysis</div>
                <div class="bar" style="width: 72%;">
                    <span class="bar-value">72% adoption</span>
                </div>
            </div>
            <div class="bar-item">
                <div class="bar-label">Document Processing</div>
                <div class="bar" style="width: 68%;">
                    <span class="bar-value">68% adoption</span>
                </div>
            </div>
            <div class="bar-item">
                <div class="bar-label">Speech Recognition</div>
                <div class="bar" style="width: 61%;">
                    <span class="bar-value">61% adoption</span>
                </div>
            </div>
        </div>
        <p style="margin-top: 20px; font-size: 0.95em; color: #666;">Source: Gartner NLP Market Analysis 2024</p>
    </div>

    <!-- Slide 7: Text Pre-processing Overview -->
    <div class="slide">
        <h2>Text Pre-processing Pipeline</h2>
        <p>Before machines can analyze text, raw text must be transformed into a structured format. This involves several essential steps:</p>
        
        <div class="process-flow" style="flex-direction: column; align-items: stretch;">
            <div class="process-step">
                <h4>1. Tokenization</h4>
                <p>Breaking text into individual words or tokens</p>
            </div>
            <div style="text-align: center; font-size: 2em; color: #C41E3A;">↓</div>
            <div class="process-step">
                <h4>2. Cleaning</h4>
                <p>Remove punctuation, special characters, and noise</p>
            </div>
            <div style="text-align: center; font-size: 2em; color: #C41E3A;">↓</div>
            <div class="process-step">
                <h4>3. Stop Word Removal</h4>
                <p>Filter out common words with little meaning (a, an, the)</p>
            </div>
            <div style="text-align: center; font-size: 2em; color: #C41E3A;">↓</div>
            <div class="process-step">
                <h4>4. Normalization</h4>
                <p>Stemming or lemmatization to standardize word forms</p>
            </div>
        </div>
    </div>

    <!-- Slide 8: Tokenization Example -->
    <div class="slide">
        <h2>Step 1: Tokenization</h2>
        <p>Tokenization breaks continuous text into discrete units (tokens), typically words or subwords.</p>
        
        <div class="example-box">
            <h4>Original Text</h4>
            <p style="font-size: 1.3em; font-style: italic;">"The product works well! I would recommend this product to others."</p>
        </div>
        
        <div class="example-box" style="margin-top: 30px;">
            <h4>After Tokenization</h4>
            <div style="display: flex; flex-wrap: wrap; gap: 10px; margin-top: 15px;">
                <span style="padding: 8px 15px; background: #C41E3A; color: white; border-radius: 5px;">The</span>
                <span style="padding: 8px 15px; background: #C41E3A; color: white; border-radius: 5px;">product</span>
                <span style="padding: 8px 15px; background: #C41E3A; color: white; border-radius: 5px;">works</span>
                <span style="padding: 8px 15px; background: #C41E3A; color: white; border-radius: 5px;">well</span>
                <span style="padding: 8px 15px; background: #C41E3A; color: white; border-radius: 5px;">!</span>
                <span style="padding: 8px 15px; background: #C41E3A; color: white; border-radius: 5px;">I</span>
                <span style="padding: 8px 15px; background: #C41E3A; color: white; border-radius: 5px;">would</span>
                <span style="padding: 8px 15px; background: #C41E3A; color: white; border-radius: 5px;">recommend</span>
                <span style="padding: 8px 15px; background: #C41E3A; color: white; border-radius: 5px;">this</span>
                <span style="padding: 8px 15px; background: #C41E3A; color: white; border-radius: 5px;">product</span>
                <span style="padding: 8px 15px; background: #C41E3A; color: white; border-radius: 5px;">to</span>
                <span style="padding: 8px 15px; background: #C41E3A; color: white; border-radius: 5px;">others</span>
                <span style="padding: 8px 15px; background: #C41E3A; color: white; border-radius: 5px;">.</span>
            </div>
        </div>
        
        <div class="highlight" style="margin-top: 30px;">
            <p><strong>Result:</strong> 13 individual tokens that can be analyzed independently</p>
        </div>
    </div>

    <!-- Slide 9: Stop Word Removal -->
    <div class="slide">
        <h2>Step 2: Stop Word Removal</h2>
        <p>Stop words are common words that appear frequently but carry little semantic meaning. Removing them reduces noise and computational complexity.</p>
        
        <div class="example-box">
            <h4>Common Stop Words</h4>
            <div style="display: flex; flex-wrap: wrap; gap: 10px; margin-top: 15px;">
                <span style="padding: 8px 15px; background: #e0e0e0; border-radius: 5px;">the</span>
                <span style="padding: 8px 15px; background: #e0e0e0; border-radius: 5px;">a</span>
                <span style="padding: 8px 15px; background: #e0e0e0; border-radius: 5px;">an</span>
                <span style="padding: 8px 15px; background: #e0e0e0; border-radius: 5px;">is</span>
                <span style="padding: 8px 15px; background: #e0e0e0; border-radius: 5px;">to</span>
                <span style="padding: 8px 15px; background: #e0e0e0; border-radius: 5px;">in</span>
                <span style="padding: 8px 15px; background: #e0e0e0; border-radius: 5px;">of</span>
                <span style="padding: 8px 15px; background: #e0e0e0; border-radius: 5px;">I</span>
                <span style="padding: 8px 15px; background: #e0e0e0; border-radius: 5px;">would</span>
                <span style="padding: 8px 15px; background: #e0e0e0; border-radius: 5px;">this</span>
            </div>
        </div>
        
        <div class="two-column" style="margin-top: 40px;">
            <div class="example-box">
                <h4>Before Removal</h4>
                <p>The, product, works, well, I, would, recommend, this, product, to, others</p>
                <p style="margin-top: 15px; color: #C41E3A;"><strong>11 tokens</strong></p>
            </div>
            <div class="example-box">
                <h4>After Removal</h4>
                <p>product, works, well, recommend, product, others</p>
                <p style="margin-top: 15px; color: #C41E3A;"><strong>6 tokens</strong></p>
            </div>
        </div>
        
        <div class="highlight" style="margin-top: 30px;">
            <p><strong>Impact:</strong> 45% reduction in tokens while preserving core meaning</p>
        </div>
    </div>

    <!-- Slide 10: Stemming vs Lemmatization -->
    <div class="slide">
        <h2>Step 3: Text Normalization</h2>
        <p>Normalization reduces words to their base or root form, helping machines recognize that different forms represent the same concept.</p>
        
        <div class="two-column">
            <div>
                <h3>Stemming</h3>
                <div class="example-box">
                    <p><strong>Definition:</strong> Crude rule-based cutting of word endings</p>
                    <p style="margin-top: 15px;"><strong>Examples:</strong></p>
                    <ul style="margin-left: 20px;">
                        <li>running → run</li>
                        <li>worked → work</li>
                        <li>better → better</li>
                        <li>caring → car (error!)</li>
                    </ul>
                    <p style="margin-top: 15px; color: #C41E3A;"><strong>Advantage:</strong> Fast and simple</p>
                    <p style="color: #666;"><strong>Limitation:</strong> Can produce non-words</p>
                </div>
            </div>
            
            <div>
                <h3>Lemmatization</h3>
                <div class="example-box">
                    <p><strong>Definition:</strong> Linguistically informed reduction to dictionary form</p>
                    <p style="margin-top: 15px;"><strong>Examples:</strong></p>
                    <ul style="margin-left: 20px;">
                        <li>running → run</li>
                        <li>worked → work</li>
                        <li>better → good</li>
                        <li>caring → care</li>
                    </ul>
                    <p style="margin-top: 15px; color: #C41E3A;"><strong>Advantage:</strong> Always produces valid words</p>
                    <p style="color: #666;"><strong>Limitation:</strong> Slower, requires language models</p>
                </div>
            </div>
        </div>
    </div>

    <!-- Slide 11: Complete Pre-processing Example -->
    <div class="slide">
        <h2>Complete Pre-processing Pipeline</h2>
        <p>Let's see how all steps transform a customer review:</p>
        
        <div style="margin: 30px 0;">
            <div class="example-box">
                <h4>Original Review</h4>
                <p style="font-size: 1.3em; font-style: italic;">"The product works amazingly well! I would definitely recommend this product to other customers."</p>
            </div>
            
            <div style="text-align: center; margin: 20px 0; font-size: 2em; color: #C41E3A;">↓</div>
            
            <div class="example-box">
                <h4>Step 1: Tokenization</h4>
                <p>The | product | works | amazingly | well | ! | I | would | definitely | recommend | this | product | to | other | customers | .</p>
            </div>
            
            <div style="text-align: center; margin: 20px 0; font-size: 2em; color: #C41E3A;">↓</div>
            
            <div class="example-box">
                <h4>Step 2: Remove Punctuation & Stop Words</h4>
                <p>product | works | amazingly | well | definitely | recommend | product | customers</p>
            </div>
            
            <div style="text-align: center; margin: 20px 0; font-size: 2em; color: #C41E3A;">↓</div>
            
            <div class="example-box">
                <h4>Step 3: Lemmatization</h4>
                <p>product | work | amazing | well | definite | recommend | product | customer</p>
            </div>
        </div>
        
        <div class="highlight">
            <p><strong>Final Result:</strong> Clean, normalized tokens ready for machine learning analysis</p>
        </div>
    </div>

    <!-- Slide 12: Quiz 1 -->
    <div class="slide">
        <h2>Knowledge Check: Text Pre-processing</h2>
        <div class="quiz-container">
            <div class="quiz-question">Which pre-processing step would be most important for reducing the vocabulary size in a sentiment analysis model?</div>
            <div class="quiz-options">
                <div class="quiz-option" data-quiz="1" data-option="a">
                    A) Tokenization only
                </div>
                <div class="quiz-option" data-quiz="1" data-option="b">
                    B) Stop word removal only
                </div>
                <div class="quiz-option" data-quiz="1" data-option="c" data-correct="true">
                    C) Lemmatization combined with stop word removal
                </div>
                <div class="quiz-option" data-quiz="1" data-option="d">
                    D) Keeping all words in their original form
                </div>
            </div>
            <div class="quiz-feedback" data-quiz="1"></div>
        </div>
    </div>

    <!-- Slide 13: Bag of Words Model -->
    <div class="slide">
        <h2>Bag-of-Words Model</h2>
        <p>The Bag-of-Words (BoW) model represents text as a collection of word frequencies, ignoring grammar and word order.</p>
        
        <h3>How It Works</h3>
        <div class="process-flow" style="flex-wrap: nowrap;">
            <div class="process-step">
                <h4>Step 1</h4>
                <p>Create vocabulary of all unique words</p>
            </div>
            <span class="arrow">→</span>
            <div class="process-step">
                <h4>Step 2</h4>
                <p>Count word occurrences in each document</p>
            </div>
            <span class="arrow">→</span>
            <div class="process-step">
                <h4>Step 3</h4>
                <p>Represent as numerical vector</p>
            </div>
        </div>
        
        <div class="example-box" style="margin-top: 40px;">
            <h4>Example: Vocabulary</h4>
            <p style="font-size: 1.1em;">["bad", "good", "great", "product", "recommend", "terrible", "well"]</p>
        </div>
        
        <div class="two-column" style="margin-top: 30px;">
            <div class="example-box">
                <h4>Review 1</h4>
                <p>"The product works well! I would recommend the product."</p>
                <p style="margin-top: 15px; font-family: monospace; color: #C41E3A;">[0, 0, 0, 2, 1, 0, 1]</p>
            </div>
            <div class="example-box">
                <h4>Review 2</h4>
                <p>"Terrible product. Bad quality, not good."</p>
                <p style="margin-top: 15px; font-family: monospace; color: #C41E3A;">[1, 1, 0, 1, 0, 1, 0]</p>
            </div>
        </div>
    </div>

    <!-- Slide 14: Limitations of Bag of Words -->
    <div class="slide">
        <h2>Limitations of Bag-of-Words</h2>
        
        <div class="two-column">
            <div>
                <h3>What BoW Captures</h3>
                <div class="example-box" style="background: #d4edda;">
                    <ul>
                        <li>Word frequency information</li>
                        <li>Vocabulary presence/absence</li>
                        <li>Simple pattern recognition</li>
                        <li>Computational efficiency</li>
                    </ul>
                </div>
            </div>
            
            <div>
                <h3>What BoW Misses</h3>
                <div class="example-box" style="background: #f8d7da;">
                    <ul>
                        <li>Word order and grammar</li>
                        <li>Context and relationships</li>
                        <li>Semantic meaning</li>
                        <li>Negations ("not good")</li>
                    </ul>
                </div>
            </div>
        </div>
        
        <div class="example-box" style="margin-top: 40px;">
            <h4>Critical Example</h4>
            <div class="two-column">
                <div>
                    <p><strong>Sentence 1:</strong> "The product is not terrible"</p>
                    <p style="color: #C41E3A; margin-top: 10px;">Vector: [0, 0, 0, 1, 0, 1, 0]</p>
                </div>
                <div>
                    <p><strong>Sentence 2:</strong> "The product is terrible"</p>
                    <p style="color: #C41E3A; margin-top: 10px;">Vector: [0, 0, 0, 1, 0, 1, 0]</p>
                </div>
            </div>
            <p style="margin-top: 20px; font-weight: bold; color: #C41E3A;">Problem: Opposite meanings produce identical vectors!</p>
        </div>
        
        <div class="highlight" style="margin-top: 30px;">
            <p>Despite limitations, BoW remains effective for many classification tasks and serves as foundation for more advanced methods.</p>
        </div>
    </div>

    <!-- Slide 15: Introduction to Naive Bayes -->
    <div class="slide">
        <h2>Naïve Bayes Classifier</h2>
        <p>Naïve Bayes is a probabilistic classification algorithm based on Bayes' Theorem, with an assumption of independence between features.</p>
        
        <div class="viz-container">
            <h3>Core Concept</h3>
            <p style="font-size: 1.2em;">Given a document with words, calculate the probability it belongs to each category (Positive, Negative, Neutral)</p>
            
            <div class="example-box" style="margin-top: 30px;">
                <h4>Bayes' Theorem (Simplified)</h4>
                <p style="font-size: 1.3em; text-align: center; margin: 20px 0;">
                    P(Category | Words) = [P(Words | Category) × P(Category)] / P(Words)
                </p>
                <ul style="margin-top: 20px;">
                    <li><strong>P(Category | Words):</strong> Probability review is positive given these words</li>
                    <li><strong>P(Words | Category):</strong> Probability these words appear in positive reviews</li>
                    <li><strong>P(Category):</strong> Overall proportion of positive reviews</li>
                </ul>
            </div>
        </div>
        
        <div class="highlight" style="margin-top: 30px;">
            <p><strong>"Naïve" Assumption:</strong> The algorithm assumes words are independent (appearing of one word doesn't affect others). While unrealistic, this simplification makes computation tractable and often works well in practice.</p>
        </div>
    </div>

    <!-- Slide 16: Naive Bayes Training -->
    <div class="slide">
        <h2>Training a Naïve Bayes Classifier</h2>
        <p>The model learns from labeled training data by calculating word probabilities for each category.</p>
        
        <div class="example-box">
            <h4>Training Dataset Example (Hotel Reviews)</h4>
            <table class="comparison-table" style="margin-top: 20px;">
                <tr>
                    <th>Review</th>
                    <th>Words Present</th>
                    <th>Label</th>
                </tr>
                <tr>
                    <td>"Great location, clean rooms"</td>
                    <td>great, location, clean, room</td>
                    <td style="color: #27ae60; font-weight: bold;">Positive</td>
                </tr>
                <tr>
                    <td>"Terrible service, dirty bathroom"</td>
                    <td>terrible, service, dirty, bathroom</td>
                    <td style="color: #e74c3c; font-weight: bold;">Negative</td>
                </tr>
                <tr>
                    <td>"Excellent staff, would recommend"</td>
                    <td>excellent, staff, recommend</td>
                    <td style="color: #27ae60; font-weight: bold;">Positive</td>
                </tr>
                <tr>
                    <td>"Poor value, noisy location"</td>
                    <td>poor, value, noisy, location</td>
                    <td style="color: #e74c3c; font-weight: bold;">Negative</td>
                </tr>
                <tr>
                    <td>"Good breakfast, friendly staff"</td>
                    <td>good, breakfast, friendly, staff</td>
                    <td style="color: #27ae60; font-weight: bold;">Positive</td>
                </tr>
            </table>
        </div>
        
        <div class="two-column" style="margin-top: 40px;">
            <div class="stat-box">
                <span class="stat-number">60%</span>
                <span class="stat-label">Positive Reviews</span>
            </div>
            <div class="stat-box">
                <span class="stat-number">40%</span>
                <span class="stat-label">Negative Reviews</span>
            </div>
        </div>
    </div>

    <!-- Slide 17: Naive Bayes Prediction -->
    <div class="slide">
        <h2>Making Predictions with Naïve Bayes</h2>
        <p>Let's classify a new review: <strong>"Great staff and good location"</strong></p>
        
        <div class="process-flow" style="flex-direction: column; align-items: stretch;">
            <div class="process-step">
                <h4>Step 1: Extract Words</h4>
                <p>Words: ["great", "staff", "good", "location"]</p>
            </div>
            
            <div style="text-align: center; font-size: 2em; color: #C41E3A;">↓</div>
            
            <div class="process-step">
                <h4>Step 2: Calculate Probabilities</h4>
                <div class="two-column" style="margin-top: 15px;">
                    <div>
                        <p><strong>For Positive:</strong></p>
                        <ul style="font-size: 0.95em; margin-left: 20px;">
                            <li>"great" appears in 2/3 positive reviews</li>
                            <li>"staff" appears in 2/3 positive reviews</li>
                            <li>"good" appears in 1/3 positive reviews</li>
                            <li>"location" appears in 1/3 positive reviews</li>
                        </ul>
                    </div>
                    <div>
                        <p><strong>For Negative:</strong></p>
                        <ul style="font-size: 0.95em; margin-left: 20px;">
                            <li>"great" appears in 0/2 negative reviews</li>
                            <li>"staff" appears in 0/2 negative reviews</li>
                            <li>"good" appears in 0/2 negative reviews</li>
                            <li>"location" appears in 1/2 negative reviews</li>
                        </ul>
                    </div>
                </div>
            </div>
            
            <div style="text-align: center; font-size: 2em; color: #C41E3A;">↓</div>
            
            <div class="process-step" style="background: #d4edda;">
                <h4>Step 3: Final Prediction</h4>
                <p style="font-size: 1.2em;"><strong>Positive: 87% probability</strong></p>
                <p style="font-size: 1.2em;"><strong>Negative: 13% probability</strong></p>
                <p style="margin-top: 15px; color: #27ae60; font-weight: bold;">Classification: POSITIVE</p>
            </div>
        </div>
    </div>

    <!-- Slide 18: Laplace Smoothing -->
    <div class="slide">
        <h2>The Zero-Probability Problem</h2>
        <p>What happens when a word never appears in training data for a particular category?</p>
        
        <div class="example-box" style="background: #f8d7da;">
            <h4>Problem Scenario</h4>
            <p>New review: "The breakfast was excellent"</p>
            <p style="margin-top: 15px;">If "excellent" never appeared in negative reviews during training, then:</p>
            <p style="font-size: 1.2em; margin: 20px 0; text-align: center; color: #C41E3A;">P(excellent | Negative) = 0</p>
            <p style="font-weight: bold;">Result: Entire probability calculation becomes 0, regardless of other words!</p>
        </div>
        
        <h3 style="margin-top: 40px;">Solution: Laplace Smoothing</h3>
        <div class="example-box" style="background: #d4edda;">
            <p>Add a small count (typically 1) to all word frequencies, ensuring no probability is exactly zero.</p>
            
            <div class="two-column" style="margin-top: 20px;">
                <div>
                    <h4>Without Smoothing</h4>
                    <p>"excellent" in negative: 0/100 = 0%</p>
                    <p style="color: #e74c3c;">Causes complete failure</p>
                </div>
                <div>
                    <h4>With Smoothing</h4>
                    <p>"excellent" in negative: 1/105 = 0.95%</p>
                    <p style="color: #27ae60;">Small but non-zero probability</p>
                </div>
            </div>
        </div>
        
        <div class="highlight" style="margin-top: 30px;">
            <p><strong>Impact:</strong> Smoothing prevents model breakdown while minimally affecting overall accuracy</p>
        </div>
    </div>

    <!-- Slide 19: Naive Bayes Performance -->
    <div class="slide">
        <h2>Naïve Bayes in Practice</h2>
        
        <div class="two-column">
            <div>
                <h3>Strengths</h3>
                <div class="example-box" style="background: #d4edda;">
                    <ul>
                        <li>Fast training and prediction</li>
                        <li>Works well with small datasets</li>
                        <li>Handles high-dimensional data</li>
                        <li>Transparent and explainable</li>
                        <li>Requires minimal tuning</li>
                    </ul>
                </div>
            </div>
            
            <div>
                <h3>Limitations</h3>
                <div class="example-box" style="background: #f8d7da;">
                    <ul>
                        <li>Independence assumption often violated</li>
                        <li>Cannot capture word order</li>
                        <li>Struggles with sarcasm</li>
                        <li>Limited context understanding</li>
                        <li>Requires labeled training data</li>
                    </ul>
                </div>
            </div>
        </div>
        
        <h3 style="margin-top: 40px;">Real-World Performance Metrics</h3>
        <div class="bar-chart">
            <div class="bar-item">
                <div class="bar-label">Spam Detection</div>
                <div class="bar" style="width: 95%;">
                    <span class="bar-value">95% accuracy</span>
                </div>
            </div>
            <div class="bar-item">
                <div class="bar-label">Sentiment Analysis (Simple)</div>
                <div class="bar" style="width: 82%;">
                    <span class="bar-value">82% accuracy</span>
                </div>
            </div>
            <div class="bar-item">
                <div class="bar-label">Document Classification</div>
                <div class="bar" style="width: 88%;">
                    <span class="bar-value">88% accuracy</span>
                </div>
            </div>
            <div class="bar-item">
                <div class="bar-label">Sentiment Analysis (Complex)</div>
                <div class="bar" style="width: 68%;">
                    <span class="bar-value">68% accuracy</span>
                </div>
            </div>
        </div>
    </div>

    <!-- Slide 20: Quiz 2 -->
    <div class="slide">
        <h2>Knowledge Check: Naïve Bayes</h2>
        <div class="quiz-container">
            <div class="quiz-question">Why is Laplace smoothing necessary in Naïve Bayes classifiers?</div>
            <div class="quiz-options">
                <div class="quiz-option" data-quiz="2" data-option="a">
                    A) To increase the accuracy of the model
                </div>
                <div class="quiz-option" data-quiz="2" data-option="b" data-correct="true">
                    B) To prevent zero probabilities when a word hasn't appeared in training data
                </div>
                <div class="quiz-option" data-quiz="2" data-option="c">
                    C) To reduce computational complexity
                </div>
                <div class="quiz-option" data-quiz="2" data-option="d">
                    D) To handle multiple languages
                </div>
            </div>
            <div class="quiz-feedback" data-quiz="2"></div>
        </div>
    </div>

    <!-- Slide 21: Transition to Modern NLP -->
    <div class="slide">
        <h2>The Evolution: From Statistics to Neural Networks</h2>
        
        <div class="timeline">
            <div class="timeline-item">
                <div class="timeline-year">2000s</div>
                <div class="timeline-content">
                    <h4>Statistical NLP</h4>
                    <p>Bag-of-Words, Naïve Bayes, TF-IDF</p>
                    <p style="color: #C41E3A; margin-top: 10px;"><strong>Limitation:</strong> No understanding of context or meaning</p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-year">2013</div>
                <div class="timeline-content">
                    <h4>Word Embeddings</h4>
                    <p>Word2Vec, GloVe - words represented as dense vectors</p>
                    <p style="color: #C41E3A; margin-top: 10px;"><strong>Breakthrough:</strong> Captured semantic relationships (king - man + woman ≈ queen)</p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-year">2017</div>
                <div class="timeline-content">
                    <h4>Transformer Revolution</h4>
                    <p>"Attention is All You Need" paper introduced transformers</p>
                    <p style="color: #C41E3A; margin-top: 10px;"><strong>Innovation:</strong> Attention mechanism allows models to focus on relevant words</p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-year">2018-2025</div>
                <div class="timeline-content">
                    <h4>Large Language Models Era</h4>
                    <p>GPT series, BERT, Claude, DeepSeek</p>
                    <p style="color: #C41E3A; margin-top: 10px;"><strong>Capability:</strong> Human-like text understanding and generation</p>
                </div>
            </div>
        </div>
    </div>

    <!-- Slide 22: What Changed -->
    <div class="slide">
        <h2>Key Innovation: The Transformer Architecture</h2>
        <p>Transformers fundamentally changed how machines process language by introducing the "attention mechanism"</p>
        
        <h3>The Core Concept</h3>
        <div class="example-box">
            <p style="font-size: 1.2em;">Traditional models process words sequentially (left to right)</p>
            <p style="font-size: 1.2em; margin-top: 15px;">Transformers process <strong>all words simultaneously</strong>, with attention determining which words are most relevant to each other</p>
        </div>
        
        <div class="viz-container" style="margin-top: 40px;">
            <h4>Example: Translating "The animal didn't cross the street because it was too tired"</h4>
            
            <div class="two-column" style="margin-top: 20px;">
                <div>
                    <h4 style="color: #C41E3A;">Traditional Approach</h4>
                    <p>Processes word-by-word, may lose context of what "it" refers to by the time it reaches "tired"</p>
                </div>
                <div>
                    <h4 style="color: #C41E3A;">Transformer Approach</h4>
                    <p>Simultaneously considers all words, correctly identifies "it" refers to "animal" (not "street") based on "tired"</p>
                </div>
            </div>
        </div>
        
        <div class="highlight" style="margin-top: 30px;">
            <p><strong>Result:</strong> Much better understanding of context, relationships, and meaning across entire documents</p>
        </div>
    </div>

    <!-- Slide 23: Transformer Architecture -->
    <div class="slide">
        <h2>Transformer Components</h2>
        
        <div class="architecture">
            <div class="arch-box" style="background: #ffebee;">
                <h4>Input Text</h4>
                <p>"Translate this to Spanish"</p>
            </div>
            
            <span class="arrow">→</span>
            
            <div class="arch-box" style="background: #e8f5e9;">
                <h4>Encoder</h4>
                <p>Understands input context</p>
                <p style="font-size: 0.9em; color: #666; margin-top: 10px;">Multiple layers with attention</p>
            </div>
            
            <span class="arrow">→</span>
            
            <div class="arch-box" style="background: #e3f2fd;">
                <h4>Decoder</h4>
                <p>Generates output</p>
                <p style="font-size: 0.9em; color: #666; margin-top: 10px;">Attends to encoder + previous words</p>
            </div>
            
            <span class="arrow">→</span>
            
            <div class="arch-box" style="background: #fff3e0;">
                <h4>Output Text</h4>
                <p>"Traduce esto al español"</p>
            </div>
        </div>
        
        <h3 style="margin-top: 50px;">Attention Mechanism in Action</h3>
        <div class="example-box">
            <p style="font-size: 1.1em;">When translating "The cat sat on the mat":</p>
            <ul style="margin-top: 15px;">
                <li><strong>"cat"</strong> pays high attention to "The" (for gender in French: le/la)</li>
                <li><strong>"sat"</strong> pays high attention to "cat" (subject-verb agreement)</li>
                <li><strong>"mat"</strong> pays attention to "on" (preposition relationship)</li>
            </ul>
            <p style="margin-top: 20px; color: #C41E3A; font-weight: bold;">Each word dynamically focuses on the most relevant other words</p>
        </div>
    </div>

    <!-- Slide 24: Quiz 3 -->
    <div class="slide">
        <h2>Knowledge Check: Transformers</h2>
        <div class="quiz-container">
            <div class="quiz-question">What is the primary advantage of the attention mechanism in transformers compared to traditional sequential models?</div>
            <div class="quiz-options">
                <div class="quiz-option" data-quiz="3" data-option="a">
                    A) It processes text faster
                </div>
                <div class="quiz-option" data-quiz="3" data-option="b">
                    B) It requires less training data
                </div>
                <div class="quiz-option" data-quiz="3" data-option="c" data-correct="true">
                    C) It can consider relationships between all words simultaneously, regardless of distance
                </div>
                <div class="quiz-option" data-quiz="3" data-option="d">
                    D) It uses less computer memory
                </div>
            </div>
            <div class="quiz-feedback" data-quiz="3"></div>
        </div>
    </div>

    <!-- Slide 25: Introduction to LLMs -->
    <div class="slide">
        <h2>Large Language Models (LLMs)</h2>
        <p>Large Language Models are transformer-based neural networks trained on massive text datasets to understand and generate human language.</p>
        
        <h3>What Makes Them "Large"?</h3>
        <div class="two-column">
            <div class="stat-box">
                <span class="stat-number">175B+</span>
                <span class="stat-label">Parameters (GPT-3)</span>
            </div>
            <div class="stat-box">
                <span class="stat-number">1T+</span>
                <span class="stat-label">Parameters (GPT-4 estimated)</span>
            </div>
        </div>
        
        <div class="example-box" style="margin-top: 40px;">
            <h4>What are Parameters?</h4>
            <p>Parameters are the learned weights in the neural network. More parameters generally mean:</p>
            <ul style="margin-top: 15px;">
                <li>Greater capacity to capture complex patterns</li>
                <li>Better understanding of nuanced language</li>
                <li>Ability to perform diverse tasks without specific training</li>
            </ul>
            <p style="margin-top: 20px; font-style: italic; color: #666;">For context: The human brain has approximately 100 trillion synaptic connections</p>
        </div>
        
        <div class="highlight" style="margin-top: 30px;">
            <p><strong>Key Capability:</strong> LLMs can perform tasks they weren't explicitly trained for through "emergent abilities" - complex behaviors arising from scale</p>
        </div>
    </div>

    <!-- Slide 26: GPT Evolution -->
    <div class="slide">
        <h2>Evolution of GPT Models</h2>
        
        <table class="comparison-table">
            <tr>
                <th>Model</th>
                <th>Release</th>
                <th>Parameters</th>
                <th>Key Capability</th>
                <th>Business Impact</th>
            </tr>
            <tr>
                <td>GPT-2</td>
                <td>Feb 2019</td>
                <td>1.5 billion</td>
                <td>Coherent text generation</td>
                <td>Proof of concept</td>
            </tr>
            <tr>
                <td>GPT-3</td>
                <td>May 2020</td>
                <td>175 billion</td>
                <td>Few-shot learning, improved reasoning</td>
                <td>First commercial applications</td>
            </tr>
            <tr>
                <td>GPT-3.5</td>
                <td>Jan 2022</td>
                <td>175 billion</td>
                <td>Reduced toxicity, better instruction following</td>
                <td>Foundation for ChatGPT</td>
            </tr>
            <tr>
                <td>GPT-4</td>
                <td>Mar 2023</td>
                <td>~1 trillion (est.)</td>
                <td>Multimodal (text + images), improved reasoning</td>
                <td>Professional-grade AI assistant</td>
            </tr>
            <tr>
                <td>GPT-4.0 / DeepSeek</td>
                <td>2024-2025</td>
                <td>Undisclosed</td>
                <td>Vision, audio, code, multilingual excellence</td>
                <td>Enterprise integration, specialized tasks</td>
            </tr>
        </table>
        
        <div class="two-column" style="margin-top: 40px;">
            <div class="stat-box">
                <span class="stat-number">667×</span>
                <span class="stat-label">Parameter increase (GPT-2 to GPT-4)</span>
            </div>
            <div class="stat-box">
                <span class="stat-number">$100M+</span>
                <span class="stat-label">Estimated training cost (GPT-4)</span>
            </div>
        </div>
    </div>

    <!-- Slide 27: LLM Capabilities -->
    <div class="slide">
        <h2>What LLMs Can Do</h2>
        
        <div class="process-flow" style="flex-wrap: wrap;">
            <div class="process-step">
                <h4>Text Generation</h4>
                <p>Write articles, emails, reports, creative content</p>
            </div>
            
            <div class="process-step">
                <h4>Code Generation</h4>
                <p>Write and debug code in multiple languages</p>
            </div>
            
            <div class="process-step">
                <h4>Translation</h4>
                <p>Translate between 100+ languages</p>
            </div>
            
            <div class="process-step">
                <h4>Summarization</h4>
                <p>Condense long documents into key points</p>
            </div>
            
            <div class="process-step">
                <h4>Question Answering</h4>
                <p>Answer questions based on context</p>
            </div>
            
            <div class="process-step">
                <h4>Sentiment Analysis</h4>
                <p>Detect emotion and tone in text</p>
            </div>
        </div>
        
        <h3 style="margin-top: 50px;">Comparison: Traditional NLP vs. LLMs</h3>
        <table class="comparison-table">
            <tr>
                <th>Aspect</th>
                <th>Traditional NLP</th>
                <th>Large Language Models</th>
            </tr>
            <tr>
                <td>Training Data</td>
                <td>Task-specific labeled data</td>
                <td>Massive unlabeled text corpus</td>
            </tr>
            <tr>
                <td>Context Understanding</td>
                <td>Limited (bag-of-words)</td>
                <td>Deep contextual understanding</td>
            </tr>
            <tr>
                <td>Setup Time</td>
                <td>Days-weeks for data labeling</td>
                <td>Minutes (few examples needed)</td>
            </tr>
            <tr>
                <td>Performance on New Tasks</td>
                <td>Requires retraining</td>
                <td>Immediate with prompting</td>
            </tr>
            <tr>
                <td>Cost</td>
                <td>Low (after initial development)</td>
                <td>Higher (API fees or compute)</td>
            </tr>
        </table>
    </div>

    <!-- Slide 28: LLM Training Process -->
    <div class="slide">
        <h2>How LLMs Are Trained</h2>
        
        <div class="process-flow" style="flex-direction: column; align-items: stretch;">
            <div class="process-step">
                <h4>Stage 1: Pre-training</h4>
                <p><strong>Task:</strong> Predict the next word in billions of text sequences</p>
                <p><strong>Data:</strong> Entire internet - books, websites, articles, code repositories</p>
                <p><strong>Duration:</strong> Months on thousands of GPUs</p>
                <p><strong>Cost:</strong> $10M - $100M+</p>
            </div>
            
            <div style="text-align: center; font-size: 2em; color: #C41E3A;">↓</div>
            
            <div class="process-step">
                <h4>Stage 2: Supervised Fine-tuning</h4>
                <p><strong>Task:</strong> Learn to follow instructions and format responses</p>
                <p><strong>Data:</strong> Human-labeled examples of desired behavior</p>
                <p><strong>Example:</strong> "Write a professional email rejecting a job candidate" → [Expected response]</p>
            </div>
            
            <div style="text-align: center; font-size: 2em; color: #C41E3A;">↓</div>
            
            <div class="process-step">
                <h4>Stage 3: Reinforcement Learning from Human Feedback (RLHF)</h4>
                <p><strong>Task:</strong> Learn to generate responses humans prefer</p>
                <p><strong>Process:</strong> Human evaluators rank multiple model responses; model learns from preferences</p>
                <p><strong>Goal:</strong> Helpful, harmless, honest responses</p>
            </div>
        </div>
        
        <div class="highlight" style="margin-top: 30px;">
            <p><strong>Key Insight:</strong> The model never "memorizes" the training data - it learns patterns and relationships that allow it to generate novel text</p>
        </div>
    </div>

    <!-- Slide 29: Quiz 4 -->
    <div class="slide">
        <h2>Knowledge Check: Large Language Models</h2>
        <div class="quiz-container">
            <div class="quiz-question">What is the primary advantage of LLMs over traditional supervised learning approaches for new NLP tasks?</div>
            <div class="quiz-options">
                <div class="quiz-option" data-quiz="4" data-option="a">
                    A) They are always more accurate
                </div>
                <div class="quiz-option" data-quiz="4" data-option="b" data-correct="true">
                    B) They can perform new tasks with few or no task-specific training examples
                </div>
                <div class="quiz-option" data-quiz="4" data-option="c">
                    A) They cost less to operate
                </div>
                <div class="quiz-option" data-quiz="4" data-option="d">
                    D) They process text faster
                </div>
            </div>
            <div class="quiz-feedback" data-quiz="4"></div>
        </div>
    </div>

    <!-- Slide 30: Business Applications -->
    <div class="slide">
        <h2>LLMs in Business: Real-World Applications</h2>
        
        <div class="two-column">
            <div>
                <h3>Customer Service</h3>
                <div class="example-box">
                    <p><strong>Use Case:</strong> AI-powered customer support chatbots</p>
                    <ul style="margin-top: 15px;">
                        <li>Handle 70% of common inquiries automatically</li>
                        <li>24/7 availability in multiple languages</li>
                        <li>Escalate complex issues to humans</li>
                    </ul>
                    <div class="stat-box" style="margin-top: 20px;">
                        <span class="stat-number">40%</span>
                        <span class="stat-label">Cost reduction (Gartner 2024)</span>
                    </div>
                </div>
            </div>
            
            <div>
                <h3>Content Creation</h3>
                <div class="example-box">
                    <p><strong>Use Case:</strong> Marketing content generation</p>
                    <ul style="margin-top: 15px;">
                        <li>Product descriptions</li>
                        <li>Social media posts</li>
                        <li>Email campaigns</li>
                    </ul>
                    <div class="stat-box" style="margin-top: 20px;">
                        <span class="stat-number">10×</span>
                        <span class="stat-label">Content output increase</span>
                    </div>
                </div>
            </div>
        </div>
        
        <div class="two-column" style="margin-top: 40px;">
            <div>
                <h3>Data Analysis</h3>
                <div class="example-box">
                    <p><strong>Use Case:</strong> Automated report generation from structured data</p>
                    <p style="margin-top: 15px; color: #C41E3A;">Transform databases into narrative insights without manual analysis</p>
                </div>
            </div>
            
            <div>
                <h3>Code Development</h3>
                <div class="example-box">
                    <p><strong>Use Case:</strong> GitHub Copilot, AI pair programming</p>
                    <p style="margin-top: 15px; color: #C41E3A;">Developers report 55% faster task completion (GitHub, 2023)</p>
                </div>
            </div>
        </div>
    </div>

    <!-- Slide 31: LLM Limitations -->
    <div class="slide">
        <h2>Current Limitations of LLMs</h2>
        
        <div class="example-box" style="background: #f8d7da;">
            <h3 style="margin-top: 0;">1. Hallucinations</h3>
            <p>LLMs can confidently generate false information that sounds plausible</p>
            <p style="margin-top: 10px;"><strong>Example:</strong> Asked about a non-existent book, may invent realistic-sounding plot summary</p>
        </div>
        
        <div class="example-box" style="background: #f8d7da; margin-top: 20px;">
            <h3 style="margin-top: 0;">2. Knowledge Cutoff</h3>
            <p>Models are trained on data up to a specific date - they don't know what happened after</p>
            <p style="margin-top: 10px;"><strong>Impact:</strong> Cannot provide current news, recent events, or latest research</p>
        </div>
        
        <div class="example-box" style="background: #f8d7da; margin-top: 20px;">
            <h3 style="margin-top: 0;">3. No True Understanding</h3>
            <p>LLMs pattern-match rather than comprehend - they don't have mental models of the world</p>
            <p style="margin-top: 10px;"><strong>Example:</strong> May fail at basic spatial reasoning or logical consistency</p>
        </div>
        
        <div class="example-box" style="background: #f8d7da; margin-top: 20px;">
            <h3 style="margin-top: 0;">4. Computational Cost</h3>
            <p>Running large models requires significant computing power</p>
            <p style="margin-top: 10px;"><strong>Impact:</strong> API costs can be substantial for high-volume applications</p>
        </div>
    </div>

    <!-- Slide 32: When to Use What -->
    <div class="slide">
        <h2>Decision Framework: Traditional NLP vs. LLMs</h2>
        
        <table class="comparison-table">
            <tr>
                <th>Scenario</th>
                <th>Recommended Approach</th>
                <th>Rationale</th>
            </tr>
            <tr>
                <td>Simple spam detection with 10,000 labeled emails</td>
                <td style="background: #e8f5e9;">Traditional (Naïve Bayes)</td>
                <td>Fast, cheap, explainable, high accuracy for this specific task</td>
            </tr>
            <tr>
                <td>Customer service chatbot handling diverse queries</td>
                <td style="background: #e3f2fd;">LLM (GPT-4)</td>
                <td>Needs context understanding, handles unexpected questions</td>
            </tr>
            <tr>
                <td>Regulatory document classification (banking)</td>
                <td style="background: #e8f5e9;">Traditional + LLM Hybrid</td>
                <td>Need explainability for compliance, but benefit from LLM understanding</td>
            </tr>
            <tr>
                <td>Processing 1 million reviews per day</td>
                <td style="background: #e8f5e9;">Traditional (cost considerations)</td>
                <td>Traditional: $500/month vs LLM: $50,000/month</td>
            </tr>
            <tr>
                <td>Multilingual customer support (20+ languages)</td>
                <td style="background: #e3f2fd;">LLM</td>
                <td>Training 20 traditional models vs 1 LLM</td>
            </tr>
            <tr>
                <td>Real-time sentiment monitoring dashboard</td>
                <td style="background: #e8f5e9;">Traditional</td>
                <td>Speed critical, simpler models process faster</td>
            </tr>
        </table>
        
        <div class="highlight" style="margin-top: 30px;">
            <p><strong>Best Practice:</strong> Hybrid approach - use traditional NLP for filtering/preprocessing, then LLM for complex cases requiring nuanced understanding</p>
        </div>
    </div>

    <!-- Slide 33: Ethical Use of LLMs -->
    <div class="slide">
        <h2>Ethical Considerations: LLMs in Academic Work</h2>
        
        <div class="two-column">
            <div>
                <h3 style="color: #27ae60;">Acceptable Uses</h3>
                <div class="example-box" style="background: #d4edda;">
                    <ul>
                        <li>Grammar and spelling checking</li>
                        <li>Brainstorming and idea generation</li>
                        <li>Understanding complex concepts</li>
                        <li>Generating practice questions</li>
                        <li>Debugging code errors</li>
                        <li>Translating technical concepts</li>
                    </ul>
                </div>
            </div>
            
            <div>
                <h3 style="color: #e74c3c;">Unacceptable Uses</h3>
                <div class="example-box" style="background: #f8d7da;">
                    <ul>
                        <li>Copying AI-generated text as your own</li>
                        <li>Having AI write entire essays/reports</li>
                        <li>Using AI to complete assessments</li>
                        <li>Submitting AI code without understanding</li>
                        <li>Generating fake references</li>
                    </ul>
                </div>
            </div>
        </div>
        
        <div class="highlight" style="margin-top: 40px;">
            <h3 style="margin-top: 0;">General Principle</h3>
            <p style="font-size: 1.2em;">LLMs should <strong>enhance</strong> your learning and thinking, not <strong>replace</strong> it. Your submissions should reflect your understanding, voice, and effort.</p>
        </div>
        
        <div class="example-box" style="margin-top: 30px;">
            <h4>Transparency Rule</h4>
            <p>When in doubt, declare your AI use. For example:</p>
            <p style="margin-top: 15px; font-style: italic;">"I used ChatGPT to help explain the concept of transformers in simple language, then wrote this explanation in my own words based on my understanding."</p>
        </div>
    </div>

    <!-- Slide 34: Quiz 5 (Ethics) -->
    <div class="slide">
        <h2>Knowledge Check: Ethical AI Use</h2>
        <div class="quiz-container">
            <div class="quiz-question">Which of the following represents the most ethical use of ChatGPT for a university assignment?</div>
            <div class="quiz-options">
                <div class="quiz-option" data-quiz="5" data-option="a">
                    A) Asking ChatGPT to write the entire assignment and submitting it with minor edits
                </div>
                <div class="quiz-option" data-quiz="5" data-option="b" data-correct="true">
                    B) Using ChatGPT to explain difficult concepts, then writing your assignment in your own words based on your understanding
                </div>
                <div class="quiz-option" data-quiz="5" data-option="c">
                    C) Having ChatGPT generate an outline and using it verbatim as your submission structure
                </div>
                <div class="quiz-option" data-quiz="5" data-option="d">
                    D) Asking ChatGPT to generate references for sources you haven't read
                </div>
            </div>
            <div class="quiz-feedback" data-quiz="5"></div>
        </div>
    </div>

    <!-- Slide 35: Summary -->
    <div class="slide">
        <h2>Workshop Summary</h2>
        
        <h3>Key Takeaways</h3>
        
        <div class="process-flow" style="flex-direction: column; align-items: stretch; margin-top: 30px;">
            <div class="process-step">
                <h4>1. Traditional NLP Foundation</h4>
                <p>Text pre-processing, Bag-of-Words, and Naïve Bayes remain valuable for many business applications - especially when explainability and cost are priorities</p>
            </div>
            
            <div class="process-step">
                <h4>2. Transformer Revolution</h4>
                <p>The attention mechanism enabled models to understand context and relationships across entire documents, dramatically improving NLP capabilities</p>
            </div>
            
            <div class="process-step">
                <h4>3. Large Language Models</h4>
                <p>LLMs like GPT-4 can perform diverse language tasks with minimal examples, but come with limitations including hallucinations and computational costs</p>
            </div>
            
            <div class="process-step">
                <h4>4. Strategic Tool Selection</h4>
                <p>Choose between traditional and modern approaches based on task complexity, budget, explainability needs, and scale</p>
            </div>
            
            <div class="process-step">
                <h4>5. Ethical Responsibility</h4>
                <p>Use AI as a tool to enhance your capabilities, not replace your thinking. Maintain academic integrity and transparency</p>
            </div>
        </div>
        
        <div class="highlight" style="margin-top: 40px;">
            <p style="font-size: 1.3em; text-align: center;"><strong>Next Steps:</strong> Hands-on activities with Orange Data Mining and ChatGPT to apply these concepts to real datasets</p>
        </div>
    </div>

    <!-- Navigation -->
    <div class="navigation">
        <button class="nav-btn" id="prevBtn">← Previous</button>
        <button class="nav-btn" id="nextBtn">Next →</button>
    </div>

    <script>
        let currentSlide = 0;
        const slides = document.querySelectorAll('.slide');
        const totalSlides = slides.length;
        const prevBtn = document.getElementById('prevBtn');
        const nextBtn = document.getElementById('nextBtn');
        const slideCounter = document.getElementById('slideCounter');
        const progressBar = document.getElementById('progressBar');

        // Quiz tracking
        const quizAnswers = {};

        function showSlide(n) {
            slides[currentSlide].classList.remove('active');
            currentSlide = n;
            if (currentSlide >= totalSlides) currentSlide = totalSlides - 1;
            if (currentSlide < 0) currentSlide = 0;
            
            slides[currentSlide].classList.add('active');
            slideCounter.textContent = `${currentSlide + 1} / ${totalSlides}`;
            progressBar.style.width = `${((currentSlide + 1) / totalSlides) * 100}%`;
            
            prevBtn.disabled = currentSlide === 0;
            nextBtn.disabled = currentSlide === totalSlides - 1;
            
            // Scroll to top
            window.scrollTo(0, 0);
        }

        prevBtn.addEventListener('click', () => showSlide(currentSlide - 1));
        nextBtn.addEventListener('click', () => showSlide(currentSlide + 1));

        // Keyboard navigation
        document.addEventListener('keydown', (e) => {
            if (e.key === 'ArrowLeft') showSlide(currentSlide - 1);
            if (e.key === 'ArrowRight') showSlide(currentSlide + 1);
        });

        // Quiz functionality
        document.querySelectorAll('.quiz-option').forEach(option => {
            option.addEventListener('click', function() {
                const quizNum = this.getAttribute('data-quiz');
                const isCorrect = this.getAttribute('data-correct') === 'true';
                const feedback = document.querySelector(`.quiz-feedback[data-quiz="${quizNum}"]`);
                
                // Remove previous selections
                document.querySelectorAll(`.quiz-option[data-quiz="${quizNum}"]`).forEach(opt => {
                    opt.classList.remove('selected', 'correct', 'incorrect');
                });
                
                // Mark this option
                this.classList.add('selected');
                
                if (isCorrect) {
                    this.classList.add('correct');
                    feedback.className = 'quiz-feedback show correct';
                    feedback.innerHTML = '✓ Correct! ' + getQuizExplanation(quizNum, true);
                    quizAnswers[quizNum] = true;
                } else {
                    this.classList.add('incorrect');
                    feedback.className = 'quiz-feedback show incorrect';
                    feedback.innerHTML = '✗ Incorrect. ' + getQuizExplanation(quizNum, false);
                    quizAnswers[quizNum] = false;
                }
            });
        });

        function getQuizExplanation(quizNum, correct) {
            const explanations = {
                '1': {
                    true: 'Lemmatization normalizes different word forms to their base, and stop word removal eliminates common words, both significantly reducing vocabulary size.',
                    false: 'Think about which steps reduce the number of unique words in your vocabulary.'
                },
                '2': {
                    true: 'Without smoothing, if a word never appeared in a category during training, its probability would be exactly zero, causing the entire calculation to become zero.',
                    false: 'Consider what happens when you multiply probabilities and one of them is zero.'
                },
                '3': {
                    true: 'The attention mechanism allows each word to "attend to" relevant words anywhere in the text, capturing long-range dependencies that sequential models struggle with.',
                    false: 'Think about how transformers process all words at once rather than one at a time.'
                },
                '4': {
                    true: 'LLMs leverage knowledge from pre-training on massive datasets, enabling few-shot or zero-shot learning on new tasks without task-specific training data.',
                    false: 'Consider how traditional supervised learning requires labeled training data for each new task.'
                },
                '5': {
                    true: 'This approach uses AI as a learning tool while ensuring the final work represents your own understanding and expression.',
                    false: 'Remember: AI should enhance your learning, not replace your thinking and writing.'
                }
            };
            return explanations[quizNum][correct];
        }

        // Initialize
        showSlide(0);

        // Add touch swipe support for mobile
        let touchStartX = 0;
        let touchEndX = 0;

        document.addEventListener('touchstart', e => {
            touchStartX = e.changedTouches[0].screenX;
        });

        document.addEventListener('touchend', e => {
            touchEndX = e.changedTouches[0].screenX;
            handleSwipe();
        });

        function handleSwipe() {
            if (touchEndX < touchStartX - 50) showSlide(currentSlide + 1);
            if (touchEndX > touchStartX + 50) showSlide(currentSlide - 1);
        }
    </script>
</body>
</html>